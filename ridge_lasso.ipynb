{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The purpose of this practical session is to implement a first machine learning model on a regression problem using RidgeRegression and `sklearn`. The dataset we will used is the california housing dataset since well known boston house dataset as ethical issues.\n",
    "\n",
    "This dataset consists in a description of houses by 8 features, each house being associated to a measure of its price. The goal here is to predict the price of an house given its description.\n",
    "## The dataset\n",
    " 1. Import the dataset from sklearn and check the documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fetch_california_housing in module sklearn.datasets._california_housing:\n",
      "\n",
      "fetch_california_housing(*, data_home=None, download_if_missing=True, return_X_y=False, as_frame=False)\n",
      "    Load the California housing dataset (regression).\n",
      "    \n",
      "    ==============   ==============\n",
      "    Samples total             20640\n",
      "    Dimensionality                8\n",
      "    Features                   real\n",
      "    Target           real 0.15 - 5.\n",
      "    ==============   ==============\n",
      "    \n",
      "    Read more in the :ref:`User Guide <california_housing_dataset>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data_home : str, default=None\n",
      "        Specify another download and cache folder for the datasets. By default\n",
      "        all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "    \n",
      "    download_if_missing : bool, default=True\n",
      "        If False, raise a IOError if the data is not locally available\n",
      "        instead of trying to download the data from the source site.\n",
      "    \n",
      "    return_X_y : bool, default=False\n",
      "        If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "        object.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    as_frame : bool, default=False\n",
      "        If True, the data is a pandas DataFrame including columns with\n",
      "        appropriate dtypes (numeric, string or categorical). The target is\n",
      "        a pandas DataFrame or Series depending on the number of target_columns.\n",
      "    \n",
      "        .. versionadded:: 0.23\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    dataset : :class:`~sklearn.utils.Bunch`\n",
      "        Dictionary-like object, with the following attributes.\n",
      "    \n",
      "        data : ndarray, shape (20640, 8)\n",
      "            Each row corresponding to the 8 feature values in order.\n",
      "            If ``as_frame`` is True, ``data`` is a pandas object.\n",
      "        target : numpy array of shape (20640,)\n",
      "            Each value corresponds to the average\n",
      "            house value in units of 100,000.\n",
      "            If ``as_frame`` is True, ``target`` is a pandas object.\n",
      "        feature_names : list of length 8\n",
      "            Array of ordered feature names used in the dataset.\n",
      "        DESCR : str\n",
      "            Description of the California housing dataset.\n",
      "        frame : pandas DataFrame\n",
      "            Only present when `as_frame=True`. DataFrame with ``data`` and\n",
      "            ``target``.\n",
      "    \n",
      "            .. versionadded:: 0.23\n",
      "    \n",
      "    (data, target) : tuple if ``return_X_y`` is True\n",
      "        A tuple of two ndarray. The first containing a 2D array of\n",
      "        shape (n_samples, n_features) with each row representing one\n",
      "        sample and each column representing the features. The second\n",
      "        ndarray of shape (n_samples,) containing the target samples.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    \n",
      "    This dataset consists of 20,640 samples and 9 features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "help(fetch_california_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nAn household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surpinsingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now, we want to import the dataset into two variables, namely `X` and `y`. `X` will contains the description of data, `y` the outputs associated to each data. Check the dimensions of the two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "# X,y = ...\n",
    "y = fetch_california_housing()[\"target\"]\n",
    "X=fetch_california_housing()[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "Now we will explore our dataset. \n",
    "\n",
    "1. First, plot an histogram of `y` values to check its distribution.You can have a look at `hist` function of matplotlib.pyplot module   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of target')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y)\n",
    "plt.title(\"Distribution of target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Second, we will check the 13 features included in `X`. Compute mean and standard deviation independantly for each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704  \n",
       "std       10.386050      2.135952      2.003532  \n",
       "min        0.692308     32.540000   -124.350000  \n",
       "25%        2.429741     33.930000   -121.800000  \n",
       "50%        2.818116     34.260000   -118.490000  \n",
       "75%        3.282261     37.710000   -118.010000  \n",
       "max     1243.333333     41.950000   -114.310000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X=pd.DataFrame(X, columns=fetch_california_housing()[\"feature_names\"])\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check this information globally using the `boxplot` function from matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(X.T, vert=False)\n",
    "plt.yticks(range(1,len(X.columns)+1),X.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What do you conclude from this first step ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From histogram i got that maximum value of target is approximately equal to 4000 and minimum value of target is approximately 500.\n",
    "Here there are 8 columns,firstly i used pandas, i wrote X.descripe() and i got all statictical informations about these features.\n",
    "At last from boxplots we can see that some columns do not have outliers i mean 3 columns do not have outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## Protocol\n",
    "\n",
    "Before starting to learn a model, we have to use a clear and as much as possible unbiased protocol to evaluate our model. This protocol starts by splitting the data into two sets. The first one will be used to learn the parameters of our model, the second one will be used to evaluate the performance of our learning step.\n",
    "\n",
    "1. Split the data into two subsets using the `train_test_split` method from `sklearn.model_selection` module. Use the split ratio of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "2. Now we should normalize the data according to the observation made in the first section. Take care of not using the test set to compute the parameters required to normalize the data. Compute `X_train_norm` and `X_test_norm` correspondong normalized data `X_train` and `X_test` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale data\n",
    "#Mean and std must be evaluated on train to avoid bias\n",
    "def standard_scaler(data):\n",
    "    for col in data.columns:\n",
    "        for row in data[col]:\n",
    "            row=((row-data[col].mean())/data[col].std())\n",
    "    return data\n",
    "X_scale_train=standard_scaler(X_train)\n",
    "#apply scale to X_test\n",
    "X_scale_test=standard_scaler(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14069</th>\n",
       "      <td>2.4297</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.956597</td>\n",
       "      <td>1.026042</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>2.170139</td>\n",
       "      <td>32.76</td>\n",
       "      <td>-117.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17482</th>\n",
       "      <td>4.6806</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.674419</td>\n",
       "      <td>1.051878</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>2.624329</td>\n",
       "      <td>34.44</td>\n",
       "      <td>-119.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>1.9485</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.080423</td>\n",
       "      <td>1.028571</td>\n",
       "      <td>3559.0</td>\n",
       "      <td>3.766138</td>\n",
       "      <td>33.97</td>\n",
       "      <td>-118.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19526</th>\n",
       "      <td>3.9886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.469613</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>2.453039</td>\n",
       "      <td>37.65</td>\n",
       "      <td>-120.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>3.2708</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.269802</td>\n",
       "      <td>1.066832</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>2.797030</td>\n",
       "      <td>33.97</td>\n",
       "      <td>-118.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>4.4125</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.045662</td>\n",
       "      <td>712.0</td>\n",
       "      <td>3.251142</td>\n",
       "      <td>38.27</td>\n",
       "      <td>-121.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19648</th>\n",
       "      <td>2.9135</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.349282</td>\n",
       "      <td>0.933014</td>\n",
       "      <td>647.0</td>\n",
       "      <td>3.095694</td>\n",
       "      <td>37.48</td>\n",
       "      <td>-120.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>3.1977</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.641221</td>\n",
       "      <td>0.941476</td>\n",
       "      <td>704.0</td>\n",
       "      <td>1.791349</td>\n",
       "      <td>36.58</td>\n",
       "      <td>-121.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>5.6315</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.540598</td>\n",
       "      <td>1.064103</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>2.247863</td>\n",
       "      <td>33.62</td>\n",
       "      <td>-117.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>1.3882</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.929530</td>\n",
       "      <td>1.100671</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>3.436242</td>\n",
       "      <td>32.80</td>\n",
       "      <td>-115.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13828 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "14069  2.4297      33.0  3.956597   1.026042      1250.0  2.170139     32.76   \n",
       "17482  4.6806      23.0  5.674419   1.051878      1467.0  2.624329     34.44   \n",
       "7362   1.9485      27.0  3.080423   1.028571      3559.0  3.766138     33.97   \n",
       "19526  3.9886      16.0  5.469613   0.988950      1776.0  2.453039     37.65   \n",
       "8365   3.2708      26.0  4.269802   1.066832      1130.0  2.797030     33.97   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "13123  4.4125      20.0  6.000000   1.045662       712.0  3.251142     38.27   \n",
       "19648  2.9135      27.0  5.349282   0.933014       647.0  3.095694     37.48   \n",
       "9845   3.1977      31.0  3.641221   0.941476       704.0  1.791349     36.58   \n",
       "10799  5.6315      34.0  4.540598   1.064103      1052.0  2.247863     33.62   \n",
       "2732   1.3882      15.0  3.929530   1.100671      1024.0  3.436242     32.80   \n",
       "\n",
       "       Longitude  \n",
       "14069    -117.12  \n",
       "17482    -119.81  \n",
       "7362     -118.19  \n",
       "19526    -120.97  \n",
       "8365     -118.35  \n",
       "...          ...  \n",
       "13123    -121.26  \n",
       "19648    -120.89  \n",
       "9845     -121.90  \n",
       "10799    -117.93  \n",
       "2732     -115.56  \n",
       "\n",
       "[13828 rows x 8 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14740</th>\n",
       "      <td>4.1518</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.663073</td>\n",
       "      <td>1.075472</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>4.180593</td>\n",
       "      <td>32.58</td>\n",
       "      <td>-117.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>5.7796</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.107226</td>\n",
       "      <td>0.927739</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>3.020979</td>\n",
       "      <td>33.92</td>\n",
       "      <td>-117.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20566</th>\n",
       "      <td>4.3487</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.930712</td>\n",
       "      <td>1.026217</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>2.910112</td>\n",
       "      <td>38.65</td>\n",
       "      <td>-121.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>2.4511</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.992958</td>\n",
       "      <td>1.316901</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.746479</td>\n",
       "      <td>33.20</td>\n",
       "      <td>-115.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15709</th>\n",
       "      <td>5.0049</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.319261</td>\n",
       "      <td>1.039578</td>\n",
       "      <td>649.0</td>\n",
       "      <td>1.712401</td>\n",
       "      <td>37.79</td>\n",
       "      <td>-122.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14366</th>\n",
       "      <td>4.1806</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.470046</td>\n",
       "      <td>1.055300</td>\n",
       "      <td>513.0</td>\n",
       "      <td>2.364055</td>\n",
       "      <td>32.74</td>\n",
       "      <td>-117.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14583</th>\n",
       "      <td>3.5606</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.851695</td>\n",
       "      <td>1.108051</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>2.694915</td>\n",
       "      <td>32.84</td>\n",
       "      <td>-117.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16212</th>\n",
       "      <td>3.1845</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>922.0</td>\n",
       "      <td>2.582633</td>\n",
       "      <td>37.96</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>3.5000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.635036</td>\n",
       "      <td>0.992701</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>3.985401</td>\n",
       "      <td>33.98</td>\n",
       "      <td>-118.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8746</th>\n",
       "      <td>5.0814</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.294043</td>\n",
       "      <td>1.054499</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>2.690748</td>\n",
       "      <td>33.80</td>\n",
       "      <td>-118.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6812 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "14740  4.1518      22.0  5.663073   1.075472      1551.0  4.180593     32.58   \n",
       "10101  5.7796      32.0  6.107226   0.927739      1296.0  3.020979     33.92   \n",
       "20566  4.3487      29.0  5.930712   1.026217      1554.0  2.910112     38.65   \n",
       "2670   2.4511      37.0  4.992958   1.316901       390.0  2.746479     33.20   \n",
       "15709  5.0049      25.0  4.319261   1.039578       649.0  1.712401     37.79   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "14366  4.1806      44.0  6.470046   1.055300       513.0  2.364055     32.74   \n",
       "14583  3.5606      30.0  4.851695   1.108051      1272.0  2.694915     32.84   \n",
       "16212  3.1845      47.0  4.761905   0.963585       922.0  2.582633     37.96   \n",
       "6944   3.5000      37.0  4.635036   0.992701      1092.0  3.985401     33.98   \n",
       "8746   5.0814      25.0  5.294043   1.054499      2123.0  2.690748     33.80   \n",
       "\n",
       "       Longitude  \n",
       "14740    -117.05  \n",
       "10101    -117.97  \n",
       "20566    -121.84  \n",
       "2670     -115.60  \n",
       "15709    -122.43  \n",
       "...          ...  \n",
       "14366    -117.23  \n",
       "14583    -117.18  \n",
       "16212    -121.32  \n",
       "6944     -118.09  \n",
       "8746     -118.34  \n",
       "\n",
       "[6812 rows x 8 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Another way to do is to use the `StandardScaler` class from `sklearn.preprocessing` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_norm = StandardScaler().fit_transform(X_train) \n",
    "y_train_norm = StandardScaler().fit_transform(y_train.reshape(-1,1))\n",
    "X_test_norm = StandardScaler().fit_transform(X_test)\n",
    "y_test_norm = StandardScaler().fit_transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first model\n",
    "Now our data is normalized we can try to learn our first model in a naive approach. We will use the `Ridge` class from `sklearn.linear_model` which implements the Ridge Regression scheme seen during our lessons.\n",
    "1. Learn a first model using `Ridge` class and `X_train_norm`.\n",
    "2. What is the default $\\lambda$ defined by the `Ridge` class ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First Ridge without scaling and cv\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge=Ridge()\n",
    "ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6106651395124618"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5957631570661486"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train your model on `X_train_norm` and predict the same data. Compute the mean average error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.610665102536451"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X_train_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4595601477008113"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred_train=ridge.predict(X_train_norm)\n",
    "mean_absolute_error(y_train_norm,y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now predict on `X_test_norm` and measure the MAE. What do you observe ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5961125483260756"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X_test_norm,y_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.461470085494359"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test=ridge.predict(X_test_norm)\n",
    "mean_absolute_error(y_test_norm,y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and train scores are differed a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters\n",
    "Both fit to data and regularization terms have an effect on our model parameters $\\mathbf{w}$.\n",
    "1. Print and plot the coefficients $\\mathbf{w}$. There are available from your instance of `Ridge` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72991319  0.1026037  -0.23003288  0.25033975 -0.00789217 -0.02395084\n",
      "  -0.75951912 -0.73655899]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f41b49d0910>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGhCAYAAACphlRxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeVwU9+E+8Gf25F4FBEEQ8QRvBUHwyI3RqNHEiLHBatRomjQ1tvkl1uayaWnzbVObpJp4xSQ1RuORmGiM5PRAVBA8EQ9QDlkuYZdzgd35/bFAQ0AFYZk9nvfrNa/IMMM+tOI+zHzm8xFEURRBREREZCNkUgcgIiIiag+WFyIiIrIpLC9ERERkU1heiIiIyKawvBAREZFNYXkhIiIim8LyQkRERDaF5YWIiIhsCssLERER2RSWFyIiIrIpXVJe1qxZg+DgYDg5OSEsLAyHDh265fFbtmzBiBEj4OLiAj8/PyxYsAAlJSVdEZWIiIisnMXLy7Zt27Bs2TKsXLkSqampmDBhAiZPnozs7OxWjz98+DDmzZuHhQsX4ty5c/jss89w4sQJLFq0yNJRiYiIyAYIll6YMTIyEqNHj8batWub9oWGhmLGjBmIj49vcfw//vEPrF27FleuXGna98477+DNN99ETk7ObV/PZDLh+vXrcHd3hyAInfNNEBERkUWJoojy8nL4+/tDJrvNtRXRggwGgyiXy8Vdu3Y12//cc8+JEydObPWcI0eOiCqVSty7d69oMplErVYrTpw4UVyyZEmrx9fU1Ig6na5pO3/+vAiAGzdu3Lhx42aDW05Ozm37hQIWVFxcDKPRCF9f32b7fX19odVqWz0nOjoaW7ZsQWxsLGpqalBfX4/p06fjnXfeafX4+Ph4vP766y325+TkwMPDo+PfBBEREVmcXq9HYGAg3N3db3usRctLo1/evhFF8aa3dM6fP4/nnnsOr7zyCiZNmoT8/Hy88MILWLp0KTZu3Nji+BUrVmD58uVNHzd+8x4eHiwvRERENqYtQz4sWl68vb0hl8tbXGUpLCxscTWmUXx8PMaNG4cXXngBADB8+HC4urpiwoQJeOONN+Dn59fseLVaDbVabZlvgIiIiKyORZ82UqlUCAsLQ0JCQrP9CQkJiI6ObvWcqqqqFgN15HI5APMVGyIiInJsFn9Uevny5diwYQM2bdqE9PR0PP/888jOzsbSpUsBmG/7zJs3r+n4adOmYdeuXVi7di0yMzNx5MgRPPfcc4iIiIC/v7+l4xIREZGVs/iYl9jYWJSUlGDVqlXIz8/H0KFDsW/fPgQFBQEA8vPzm835Mn/+fJSXl+Pdd9/F73//e3Tr1g333nsv/v73v1s6KhEREdkAi8/z0tX0ej00Gg10Oh0H7BIREdmI9rx/c20jIiIisiksL0RERGRTWF6IiIjIprC8EBERkU1heSEiIiKbwvJCRERENoXlhYiIiGwKy0sbVRrqselwFl7aeVrqKERERA6N5aWNSipq8cbe8/j0RA7S8/VSxyEiInJYLC9t1NvLBZOHmle0Xn8oU+I0REREjovlpR0WT+wLANiTdh35umqJ0xARETkmlpd2GBnYDRHBnqg3idh85KrUcYiIiBwSy0s7PTXBfPXlk2PZKK+pkzgNERGR42F5aad7Q3zQr4cryg31+PR4jtRxiIiIHA7LSzvJZAIWN1x92XQkC3VGk8SJiIiIHAvLyx2YMaoXvN3UyNfV4KvT16WOQ0RE5FBYXu6Ak1KO+dFBAIB1B7MgiqLEiYiIiBwHy8sdemJsEJyVcqTn63H4crHUcYiIiBwGy8sd6uaiQuyYQADAuoOctI6IiKirsLx0wMLxwZAJwKFLxTh/nUsGEBERdQWWlw4I9HTB5GHmJQM2cMkAIiKiLsHy0kFLGpcMOHUd18u4ZAAREZGlsbx00PCAbohsWDLggyNZUschIiKyeywvnWDJXearL1uP50DPJQOIiIgsiuWlE9w90AcDfNxQYajH1mPZUschIiKyaywvneDnSwZ8cOQqauu5ZAAREZGlsLx0kodH+aOHuxpafQ2+PMUlA4iIiCyF5aWTqBVyzI/uAwBYfyiTSwYQERFZCMtLJ3oiMgguKjkuaMtx8BKXDCAiIrIElpdOpHFRNi0ZsJ5LBhAREVkEy0sne3JcMOQyAYcvF+Nsnk7qOERERHaH5aWTBXq6YAqXDCAiIrIYlhcLeKrhsekvT+cjj0sGEBERdSqWFwsYFqBBVF8vGE0iPjjMJQOIiIg6U5eUlzVr1iA4OBhOTk4ICwvDoUOHbnm8wWDAypUrERQUBLVajX79+mHTpk1dEbXTPNW0ZEA2dNVcMoCIiKizWLy8bNu2DcuWLcPKlSuRmpqKCRMmYPLkycjOvvk0+rNnz8Z3332HjRs3IiMjA1u3bkVISIilo3aquwf2wEBfN1TWGrH1OJcMICIi6iyCaOHZ1CIjIzF69GisXbu2aV9oaChmzJiB+Pj4Fsfv378fc+bMQWZmJjw9Pdv9enq9HhqNBjqdDh4eHh3K3lGfJefghR2n4euhxqH/dy9UCt6lIyIiak173r8t+m5aW1uLlJQUxMTENNsfExODxMTEVs/Zs2cPwsPD8eabb6JXr14YOHAg/vCHP6C6uvWBrwaDAXq9vtlmLaaP9IePuxoFegP2cMkAIiKiTmHR8lJcXAyj0QhfX99m+319faHVals9JzMzE4cPH8bZs2exe/durF69Gjt27MAzzzzT6vHx8fHQaDRNW2BgYKd/H3dKrZBjwbhgAOZJ67hkABERUcd1yX0MQRCafSyKYot9jUwmEwRBwJYtWxAREYEpU6bgrbfewubNm1u9+rJixQrodLqmLScnxyLfw52aG9kbrio5MgrK8dPFIqnjEBER2TyLlhdvb2/I5fIWV1kKCwtbXI1p5Ofnh169ekGj0TTtCw0NhSiKyM3NbXG8Wq2Gh4dHs82aaJyVmBPRGwCwjksGEBERdZhFy4tKpUJYWBgSEhKa7U9ISEB0dHSr54wbNw7Xr19HRUVF076LFy9CJpMhICDAknEt5snx5iUDEq+UcMkAIiKiDrL4baPly5djw4YN2LRpE9LT0/H8888jOzsbS5cuBWC+7TNv3rym4+fOnQsvLy8sWLAA58+fx8GDB/HCCy/gySefhLOzs6XjWkSvbs6YOty8ZACvvhAREXWMxctLbGwsVq9ejVWrVmHkyJE4ePAg9u3bh6CgIABAfn5+szlf3NzckJCQgLKyMoSHh+NXv/oVpk2bhrffftvSUS1qccOSAXvP5CO3tEriNERERLbL4vO8dDVrmufll361IQlHLpfgyXHBeGXaYKnjEBERWQ2rmeeFmntqYj8AwKcnsqGr4pIBREREd4LlpQtNHOCNkJ7uqKo1Ysvxa1LHISIiskksL11IEISmsS8fHLkKQ71R4kRERES2h+Wli00b4Y+eHk4oKjfgizQuGUBERNReLC9dTKWQYcG4PgDMSwaYTHY1XpqIiMjiWF4k8Hhkb7ipFbhUWMElA4iIiNqJ5UUCHk5KPB5hXkDy/YNXJE5DRERkW1heJLJgXDAUMgFJmTdwOrdM6jhEREQ2g+VFIv7dnDFthD8ALhlARETUHiwvEmp8bHrfmXzk3OCSAURERG3B8iKhwf4emDDAGyYR2Hg4S+o4RERENoHlRWJPTTRffdmenIOyqlqJ0xAREVk/lheJje/vjVA/D/OSAceyb38CERGRg2N5kZggCHhqYjAALhlARETUFiwvVmDqcH/4aZxQXGHA56l5UschIiKyaiwvVkApl+HJcearL+u4ZAAREdEtsbxYiTkRgXBXK3ClqBI/ZBRKHYeIiMhqsbxYCXcnJeZG9gYAvM9J64iIiG6K5cWKzB/XBwqZgONZN5CWwyUDiIiIWsPyYkX8NM6YPtK8ZMB6Xn0hIiJqFcuLlWlcMuDrs/nILuGSAURERL/E8mJlQv08MHFgj4YlA3j1hYiI6JdYXqzQUxMalwzIRWkllwwgIiL6OZYXKzSuvxcG+3mgus6I/yZdkzoOERGRVWF5sULmJQPMV18+PHoVNXVcMoCIiKgRy4uVemi4H/w1TiiuqMVuLhlARETUhOXFSinlMjw53rxkwPpDXDKAiIioEcuLFZsT0RvuTgpkFlXiuwtcMoCIiAhgebFqbmoFfhUZBICT1hERETViebFyC8b1gVIu4PjVG0jNLpU6DhERkeRYXqycr4cTHh7ZC4B57AsREZGjY3mxAY1LBuw/q8W1kkqJ0xAREUmL5cUGDOrpjrsHmZcM2HAoS+o4REREkmJ5sRGNSwZ8lpKDG1wygIiIHFiXlJc1a9YgODgYTk5OCAsLw6FDh9p03pEjR6BQKDBy5EgLJ7R+Uf28MLSXB2rqTPj4KJcMICIix2Xx8rJt2zYsW7YMK1euRGpqKiZMmIDJkycjOzv7lufpdDrMmzcP9913n6Uj2gRBEJrGvnx0lEsGEBGR47J4eXnrrbewcOFCLFq0CKGhoVi9ejUCAwOxdu3aW563ZMkSzJ07F1FRUZaOaDMeGuaHXt2cUVJZi50nc6WOQ0REJAmLlpfa2lqkpKQgJiam2f6YmBgkJibe9LwPPvgAV65cwauvvnrb1zAYDNDr9c02e6X42ZIBGw5lcckAIiJySBYtL8XFxTAajfD19W2239fXF1qtttVzLl26hJdeeglbtmyBQqG47WvEx8dDo9E0bYGBgZ2S3VrFjgmEh5MCWcWVSEgvkDoOERFRl+uSAbuCIDT7WBTFFvsAwGg0Yu7cuXj99dcxcODANn3tFStWQKfTNW05OTmdktlauakV+NVYLhlARESO6/aXNjrA29sbcrm8xVWWwsLCFldjAKC8vBzJyclITU3Fs88+CwAwmUwQRREKhQIHDhzAvffe2+wctVoNtVptuW/CCi2I7oMNhzKRfK0UKddKERbUXepIREREXcaiV15UKhXCwsKQkJDQbH9CQgKio6NbHO/h4YEzZ84gLS2taVu6dCkGDRqEtLQ0REZGWjKuzfDxcMKMxiUDePWFiIgcjEWvvADA8uXLERcXh/DwcERFRWHdunXIzs7G0qVLAZhv++Tl5eGjjz6CTCbD0KFDm53v4+MDJyenFvsd3eKJffFZSi6+Oa9FVnElgr1dpY5ERETUJSxeXmJjY1FSUoJVq1YhPz8fQ4cOxb59+xAUZB63kZ+ff9s5X6ilgb7uuGdQD/yQUYSNhzPxxoxhUkciIiLqEoIoinb1vK1er4dGo4FOp4OHh4fUcSzq6JUSPL4+CWqFDIkv3QsvN8ca+0NERPajPe/fXNvIho3t64nhARoY6k34OIlLBhARkWNgebFhzZcMuIbqWi4ZQERE9o/lxcZNHtoTAd2dcYNLBhARkYNgebFxCrkMC5uWDMiEkUsGEBGRnWN5sQOzwwOhcVbiakkVEs5zyQAiIrJvLC92wFWtwBNjewMA1h28InEaIiIiy2J5sRO/ju4DlVyGk9llSL56Q+o4REREFsPyYid83J0wc5R5yYB1XDKAiIjsGMuLHVk80TxwNyG9AJlFFRKnISIisgyWFzvS38cd94X4QBSBDYezpI5DRERkESwvduapieZJ63ak5KK4wiBxGiIios7H8mJnIoI9MSJAg9p6Ez46yiUDiIjI/rC82BlBEPDUxH4AgI+PXuWSAUREZHdYXuzQpCG+CPR0RmlVHXak5Egdh4iIqFOxvNghhVyGRePNY182HM7ikgFERGRXWF7s1GPhAejmosS1kiocOKeVOg4REVGnYXmxUy4qBeLGBgEA3j+YCVHk1RciIrIPLC92bF5UH6gUMqTllCH5WqnUcYiIiDoFy4sd6+GuxqOjzUsGvP8TlwwgIiL7wPJi5xZNMA/c/Ta9AFe4ZAAREdkBlhc716+HG+4P9QUAbDjEqy9ERGT7WF4cwJK7zFdfdp7MQ1E5lwwgIiLbxvLiAMKDumNkYLeGJQOuSh2HiIioQ1heHIAgCFjSsGDjx0nXUFVbL3EiIiKiO8fy4iBihvREkJcLyqrq8FlyrtRxiIiI7hjLi4OQywQsGh8MANhwOBP1RpPEicgW6arqkJRZwkkPiUhSLC8OZFZYILq7KJFzoxrfnCuQOg7ZmDqjCY+9n4g565Lwh89Oo44FmIgkwvLiQJxVcsRF9QEArDt4hb89U7tsPnIVFwvMcwXtPJmLpz5K5vgpIpIEy4uDmRcVBLVChlO5OhzPuiF1HLIRhfoarP72IgAgNjwQaoUMP2QUYe76YyitrJU4HRE5GpYXB+PtpsajYQEAgHUHOWkdtU381xdQWWvEyMBuiH9kGD5ZHAmNsxJpOWWY9V4i8sqqpY5IRA6E5cUBLRofDEEAvrtQiMuF5VLHISt3POsGdqfmQRCAVQ8PgUwmICzIEzuWRsFP44QrRZV4ZM0RZGj5d4mIugbLiwPq28MNDzQsGbD+YJbEacia1RtNeOWLswCAOWN6Y3hAt6bPDfB1x86nozHAxw0FegMeey+RtyKJqEuwvDiopxomrdudmofC8hqJ05C1+uR4Ni5oy6FxVuKFSYNafN6/mzM+WxqFsKDu0NfUI27jMRw4p5UgKRE5EpYXBxXexxOje3dDrdGEDxOvSh2HrFBJhQH/+CYDAPCHSYPg6apq9bhuLir8d2Ek7gvxgaHehKX/TcHW49ldGZWIHEyXlJc1a9YgODgYTk5OCAsLw6FDh2567K5du/DAAw+gR48e8PDwQFRUFL755puuiOlwnprYDwDw36RsVBr4yCs19+b+DOhr6jHE3wNzI3rf8lhnlRzvx4VhdngATCKwYtcZvP3dJT6OT0QWYfHysm3bNixbtgwrV65EamoqJkyYgMmTJyM7u/XfzA4ePIgHHngA+/btQ0pKCu655x5MmzYNqamplo7qcB4Y7Is+Xi7QVddhe3KO1HHIiqTllGFbw9+JVQ8PgVwm3PYchVyGvz86HM/cYy7FbyVcxCtfnIPRxAJDRJ1LEC38q1FkZCRGjx6NtWvXNu0LDQ3FjBkzEB8f36avMWTIEMTGxuKVV1657bF6vR4ajQY6nQ4eHh53nNtR/DfpGv70+VkEdHfGj3+4Gwo57yQ6OpNJxIw1R3A6V4dHRwfgn7NHtPtrbD6Shde/Og9RBKYM64m3Zo+Ek1JugbREZC/a8/5t0Xeq2tpapKSkICYmptn+mJgYJCYmtulrmEwmlJeXw9PTs9XPGwwG6PX6Zhu13aywAHi6qpBbWo2vz3KgJQHbk3NwOlcHd7UCL05uOUi3LeaPC8Y7j4+CUi5g3xkt5n9wHPqauk5OSkSOyqLlpbi4GEajEb6+vs32+/r6Qqtt2xvlP//5T1RWVmL27Nmtfj4+Ph4ajaZpCwwM7HBuR+KklGNeVBAA86R1HKPg2MqqavH3/RcAAMseGAgfd6c7/lpTh/tj84IIuKkVSMq8gdj3k1Co55NtRNRxXXKPQBCa3y8XRbHFvtZs3boVr732GrZt2wYfH59Wj1mxYgV0Ol3TlpPDsRvtFTfWvGTAmTwdkjI5T4cj++eBiyitqsNAX7emUtsR4/p749OnxsLbTY30fD0eWZuIrOLKTkhKRI7MouXF29sbcrm8xVWWwsLCFldjfmnbtm1YuHAhtm/fjvvvv/+mx6nVanh4eDTbqH283NR4LNy8ZMD6Q1wywFGdzdNhy7FrAIDXpw+FspPGPw3tpcGup6MR5OWC3NJqzFqbiNO5ZZ3ytYnIMVm0vKhUKoSFhSEhIaHZ/oSEBERHR9/0vK1bt2L+/Pn45JNP8NBDD1kyIjVYOL4vBAH4/kIhLhVwmndHI4oiXt1zDiYRmDbCH1H9vDr16/f2csGOpdEY2ssDJZW1mLMuCQcvFnXqaxCR47D4baPly5djw4YN2LRpE9LT0/H8888jOzsbS5cuBWC+7TNv3rym47du3Yp58+bhn//8J8aOHQutVgutVgudTmfpqA4t2NsVkwb3BMCrL45od2oeUq6VwkUlxx+nhFjkNXq4q/HpU1EY398bVbVGPLn5BD5PzbPIaxGRfbN4eYmNjcXq1auxatUqjBw5EgcPHsS+ffsQFGS+n56fn99szpf3338f9fX1eOaZZ+Dn59e0/e53v7N0VIe3uGHJgM9Tr3NgpQMpr6nDX/eZB+n+9t4B8NM4W+y13NQKbJo/BtNG+KPeJGLZtjRsYFkmonay+DwvXY3zvHTMrLWJSL5Wiqfv7ocXH7TMb+BkXd746jw2HM5CX29XfL1sAtQKy8/HYjKJ+PPe8/jgyFUAwJKJffHigyGQtWEyPCKyT1YzzwvZnsarL1uSrqGCSwbYvYsF5figYW2rV6cP6ZLiAgAymYBXpg5uKsjvH8zEHz47hTqjqUten4hsG8sLNfNAqC+CvV2hr6nHthN87NyeiaKIVxum748Z7Iu7Bvbo0tcXBAFP390P/zdrOOQyAbtS87D4o2RU1bI0E9GtsbxQMzKZgEUTggEAmw5noZ6/CdutvWfycTSzBGqFDC9PHSxZjsfCA7F+XhiclDL8mFGEx9cfw43KWsnyEJH1Y3mhFh4dHQAvVxXyyqqx90y+1HHIAioN9fjL3nQAwG/u7o9ATxdJ89wb4osti8aim4sSp3LKMOu9ROSWVkmaiYisF8sLteCklOPX0X0AmB+btrMx3QTgPz9cRr6uBoGezlhyV1+p4wAAwoK6Y8fSKPhrnJBZVIlH1ybigpZrlRFRSywv1KonxgbBSSnD2Tw9jl4pkToOdaLMooqmuXxemTrEqlZ77u/jjp2/icZAXzcU6A147L2jOJbJv39E1BzLC7XK01WF2eHmRS7XcR4OuyGKIl7/8jzqjCLuHtQD94e2vmaYlPw0zvhsSTTCg7qjvKYecZuOYz9XPCein2F5oZtaOD4YMgH4MaMIGVouGWAPEs4X4KeLRVDJZXh12pA2LZAqBY2LEv9dFIn7Q31RW2/Cb7akNK27RETE8kI3FeTligeHcskAe1FTZ8Sqr84DABZPDEawt6vEiW7NSSnHe0+MxpwxgTCJwMrdZ/Hvby9xDBYRsbzQrS2eYB7M+UVaHrQ6Lhlgy9776QpyS6vhp3HCM/f0lzpOmyjkMsQ/MgzP3WvO+69vL+JPn5+F0cQCQ+TIWF7olkb17o6IPp6oM4rY3DATK9menBtVWPvjFQDAnx4aDBeVQuJEbScIApbHDMKfHx4CQQC2HMvGM1tOoqbOKHU0IpIIywvdVtOSAce4ZICt+vNX52GoNyG6nxemDOspdZw7EhfVB/+ZOxoquQz7z2nx603HoauukzoWEUmA5YVu674QH/Tt4Yrymnp8ejz79ieQVfkxoxAHzhdAIRPw+nTrHaTbFlOG+WHzk2PgrlbgWNYNxL5/FAVcAZ3I4bC80G3JZELT2JdNh7O4eJ4NMdQb8fqX5kG686P7YICvu8SJOi66nzc+XTIWPdzVuKAtxyNrEnGlqELqWETUhVheqE1mjuoFbzcVrutq8MkxXn2xFRsPZyGruBI93NX43f0DpI7TaYb4a7Dr6Wj08XJBXlk1Zq1NRFpOmdSxiKiLsLxQmzgp5Vh6Vz8A5vETRy4XS5yIbidfV413vrsMAPjjlBC4OyklTtS5Aj1dsOPpaAwP0KC0qg6Pr0vCjxmFUscioi7A8kJttnB8MB4e6Y96k4il/03BpQJOXGfN/rI3HdV1Rozp0x0zRvaSOo5FeLup8cnisZgwwBvVdUYs+jAZu07mSh2LiCyM5YXaTBAE/P3R4RjTxzxt+4LNJ1BUbpA6FrUi8UoxvjqdD5kAvGbjg3Rvx02twMZfj2kq1su3n8K6g1ekjkVEFsTyQu3ipJTj/bhw9PFyQW5pNRZ9lIzqWs63YU3qjCa8+sU5AOYFNof4ayROZHkqhQz/mj0SC8cHAwD+uu8C/rL3PEyczI7ILrG8ULt5uqrwwYIIdHNR4lROGZZvT+ObhBX5MPEqLhVWwNNVhd8/MEjqOF1GJhPwp4dCsWJyCABg/aEs/P6zU3w6jsgOsbzQHQn2dsX7T4RBKRfw9Vkt3vwmQ+pIBKCwvAarv70EAHjxwUHQuNjXIN3bEQQBS+7qh38+NgJymYDdqXlY+GEyKjm5IpFdYXmhOxbZ1wtvzhoOwLxuzlZOYCe5v319ARWGeowI0OCxsECp40jm0bAAbJgXDmelHAcvFmHu+iSUVHB8FpG9YHmhDpk5KgDLGuYP+dPnZ3HoUpHEiRxX8tUb2HUyD4IArHp4KGQy+x2k2xb3hPjgk8WR6O6ixKlcHWa9dxQ5N6qkjkVEnYDlhTrsd/cNwMxRvWA0ifjNf08iQ8tHqLua0STilYZBurHhgRgR2E3iRNZhVO/u2PF0NHp1c0ZWcSUeXZuI9Hy91LGIqINYXqjDBEHA3x4dhohgT5Qb6vHk5hMoLOd6M13pk2PXcD5fDw8nBV6Y5DiDdNuiXw837Hw6GoN83VFYbsDs944iKbNE6lhE1AEsL9Qp1Ao53n8iDMHersgrq8biD/kIdVcpqTDg/xoGTP9h0iB4uaklTmR9emqcsH1pFCL6mAv2vE3Hsf9svtSxiOgOsbxQp+nuqsIH88c0jTFYti2Vj1B3gX8cyIC+ph6D/Tzwq8ggqeNYLY2zEh8tjEDMYF/U1pvw9JaT+G/SNaljEdEdYHmhTtXH2xXr5oVDJZfhm3MF+Nv+C1JHsmuncsrw6YkcAMCqh4dA7uCDdG/HSSnH2ifC8HhEb4iieZD5WwkXIYos2US2hOWFOt2YPp74v8fMj1CvO5iJLcf4260lmEwiXtlzDqIIPDKqF8L7eEodySbIZQL+OnMofnef+Sm5t7+7hD/uPot6TmZHZDNYXsgiHh7ZC8sfGAgAeOWLc/jpIh+h7mw7UnJxKqcMbmoFXmqYVZbaRhAEPP/AQLwxYygEAdh6PBu/2XISNXUcp0VkC1heyGJ+e29/PDLa/Aj1M1tO4oKWj6h2Fl1VXdMtuWX3D4CPh5PEiWzTE2ODsGbuaKjkMhw4X4B5G49DV10ndSwiug2WF7IYQRDwt0eGY2xfT1QY6vHkBydQqOcj1J3hrYQM3KisRX8fN/w6uo/UcWza5GF++GhhBNzVChy/egOz3zsKrY5/T+P3FIoAACAASURBVImsGcsLWZRKIcN7T4Shr7crrutqsOijZFTVcp2Zjjh/XY+PG56SWTV9CJRy/hh31Ni+Xti2JAo93NXIKCjHo2sTcbmwQupYRHQT/FePLK6biwofLBgDT1cVTufq8LtP02DkI9R3RBRFvLrnLEwi8NBwP0T395Y6kt0Y7O+BXU9HN81V9Nh7iUjNLpU6FhG1okvKy5o1axAcHAwnJyeEhYXh0KFDtzz+p59+QlhYGJycnNC3b1+89957XRGTLCjIyxXr4sKgUsiQcL4A8fvSpY5kk75Iu44TV0vhrJRj5ZRQqePYnUBPF+xYGoURARqUVtVh7vpj+CGjUOpYRPQLFi8v27Ztw7Jly7By5UqkpqZiwoQJmDx5MrKzW1+BOCsrC1OmTMGECROQmpqKP/7xj3juueewc+dOS0clCwvv44l/PDYCALDhcBY+PnpV0jy2prymDn9pKH3P3tsf/t2cJU5kn7zc1Phk8VhMHNgD1XVGLPowGTtTcqWORUQ/I4gWnp0pMjISo0ePxtq1a5v2hYaGYsaMGYiPj29x/Isvvog9e/YgPf1/v5kvXboUp06dwtGjR2/7enq9HhqNBjqdDh4eHp3zTVCnevf7S/jHgYuQCcDG+WNwzyAfqSPZhL/uS8e6g5no4+WCb56fCLVCLnUku1Zbb8KLO09jd2oeAGDF5BA8NbEvBIETARJZQnvevy165aW2thYpKSmIiYlptj8mJgaJiYmtnnP06NEWx0+aNAnJycmoq2v5CKPBYIBer2+2kXV75p7+mBUWAJMIPLvlJM5f5/9nt3OpoBybDmcBAF6dPoTFpQuoFDL887EReGpiXwBA/NcX8MbedC55QWQFLFpeiouLYTQa4evr22y/r68vtFptq+dotdpWj6+vr0dxcXGL4+Pj46HRaJq2wMDAzvsGyCIEQcBfZw5DVF8vVNYasfDDEyjgI9Q3JYoiXvvyHOpNIu4P9eWVqi4kkwn445TQpvFFGw9n4fntaSiuMMBQzwntiKSi6IoX+eVlVlEUb3nptbXjW9sPACtWrMDy5cubPtbr9SwwNqDxEepH1h7BlaJKPLn5BLYviYKrukv+StqUr89qceRyCVQKGV6dNljqOA5p8cS+8HZX4YXPTuOLtOv4Iu06APPfY3e1Au5OCrg5KeCmVsDdSfmLfUq4OymaNje1suG4xo8VUPBxd6J2seg7hbe3N+RyeYurLIWFhS2urjTq2bNnq8crFAp4eXm1OF6tVkOtVndeaOoyGhclPpgfgZlrjuDcdT1+92kq3o8L5+KCP1NVW483vjoPAHj6rn4I9HSROJHjmjkqAN1dVPjjrjO43jCJXW29CSX1tSiprO3Q13ZWyuHWWHAaCpCbWtFsn/nPvyw+yv+VJJUCMv7skIOwaHlRqVQICwtDQkICZs6c2bQ/ISEBDz/8cKvnREVF4csvv2y278CBAwgPD4dSqbRkXJJAby8XrJsXjsfXJ+Hb9EL8ZW86XuHVhSZrfriC67oaBHR3xtN395M6jsO7e5APElfcB6NJRIWhHhWGepTX1KGiph7lhnqU19Sb/1xT1/C5hn2Guob/mj+vb9hXU2deDLK6zojqOiOKyg0dyuemVjSVm8ay436zfT+78uPupGz6s4tKzkHJZPUsfo1++fLliIuLQ3h4OKKiorBu3TpkZ2dj6dKlAMy3ffLy8vDRRx8BMD9Z9O6772L58uVYvHgxjh49io0bN2Lr1q2WjkoSCQvqjrdmj8Czn6Ri05EsBHm5cMp7AFeLK7HuYCYA4OWpg+Gk5CBdayGXCdA4K6FxVgK480fWa+tNqGwoQfrGEtRQcsp/Xowa9/2iGDWWpzqj+dZ6Y6HqyDJiMgEtCo25+CibrgINC9Bg6nD/O38Rog6yeHmJjY1FSUkJVq1ahfz8fAwdOhT79u1DUFAQACA/P7/ZnC/BwcHYt28fnn/+efznP/+Bv78/3n77bTz66KOWjkoSmjrcH9k3qvDm/gy8/uU5BHo6496Q1m8tOgJRFPH6l+dQazRh4sAeiBnsuP9b2DOVQgaVQoXurqoOfZ2aOuP/Ck1NPcobr/T8vOzc8sqQeZ9JBEwioG+4OnQrfbxcMbSXpkO5ie6Uxed56Wqc58V2iaKIl3aewbbkHLio5PhsaRSG+DvmP47fni/Aoo+SoZQL+GbZRPTt4SZ1JLJzoiiius74s9tard8S+/5CAU7l6vDE2N54Y8YwqWOTHWnP+zcf7SCrIQgC3pg5FLllVThyuQQLNyfj82fGoafGSepoXaqmzojXvzoHAFg0oS+LC3UJQRDgolLARaWAzy3eN8KCuuOJjcfwRdp1/Okh3s4kafD5PLIqSrkMa34Vhv4+btDqa/Dk5hOoNDjWKtTrDmYi50Y1eno44dl7+ksdh6iZ6H5eCOjujPKaenx9Nl/qOOSgWF7I6miclfhg/hh4u6lwPl+P325NdZhVqHNuVOE/P1wGAKx8KJTz3pDVkckEzA43z6X16fEcidOQo2J5IasU6OmC9fPCoVbI8P2FQvy5Ya4Te/eXvekw1Jswtq8npg73kzoOUatmhQVAEIBjWTdwtbhS6jjkgFheyGqN6t0d/4odCQDYnHgVHxzJkjiRZR28WIT957SQywS8Pn0o59ogq+XfzRl3DewBANiezKsv1PVYXsiqTRnmh5cmhwAA/vzVeXx7vkDiRJZRW2/Ca3vMg3R/HdUHg3q6S5yI6NZiG24d7UjJRb3RJHEacjQsL2T1lkzsi8cjAmESgd9uTcXZPJ3UkTrdpiNZyCyuhLebGsseGCB1HKLbui/UF16uKhSWG/BjRpHUccjBsLyQ1RMEAaseHooJA7xRXWdehTpfVy11rE6j1dXg7e8uAQBWTA6BhxOXwSDrp1LI8MjoXgCAT0/w1hF1LZYXsglKuQz/+dVoDPBxQ4HegCc3J6PCTh6h/uu+dFTVGhEW1B0zR/WSOg5Rm8WOMd86+iGjEIX6GonTkCNheSGb4eGkxKb5Y+DtpkZ6vh6//eSkzd9rT8oswZ5T1yEIwOvTh3BVYLIp/X3cERbUHUaTiJ0n86SOQw6E5YVsSqCnCzb8OhxOShl+yCjC61+eh62ucFFnNOHVL8yDdH8V2ZvrxJBNahy4uz05x2Z/Fsn2sLyQzRkZ2A2rY0dCEICPk65h05GrUke6Ix8fvYaMgnJ0d1HiDzGDpI5DdEceGu4HV5UcWcWVOJ51Q+o45CBYXsgmPTjUDysaHqF+Y+95HDinlThR+xSVG/CvhIsAgP/3YAi6uXRsVWEiqbiqFZg2wh8AsI0Dd6mLsLyQzVo8oS/mRvaGKAK/+zQNZ3Jt5xHqv++/gHJDPYYHaJqmWieyVbMbBu7uO5sPfU2dxGnIEbC8kM0SBAGrpg/BxIE9UF1nxJMfnkBemfU/Qp1yrRQ7UnIBmAfpyjlIl2zcqMBuGOjrhpo6E/akXZc6DjkAlheyaQq5DP+ZOwqDfN1RVG7Aws0nUG7Fv/kZTSJe3XMWADA7PACjeneXOBFRxwnC/xZr5K0j6gosL2Tz3J2U2LRgDHq4q3FBW45nP0m12keotx7Pxtk8PdydFPh/D4ZIHYeo0zwyOgBKuYAzeTqcv66XOg7ZOZYXsgu9ujljY8Mj1D9dLMKre85Z3WObpZW1+MeBDADA7x8YCG83tcSJiDqPp6sKMYN7AuBijWR5LC9kN4YHdMO/54yCIABbjmVj42HrWoX6/w5koKyqDiE93fHE2CCp4xB1usaBu7tT81BTZ5Q4DdkzlheyK5OG9MTKKaEAgL/sS8c3VvII9ZlcHbYezwYArHp4KBRy/uiR/Rnf3xv+Gifoquus5meP7BP/BSW7s3B8MJ4Y2/gIdSpO55ZJmsdkEvHKnrMQRWDGSH9EBHtKmofIUuQyAY9x4C51AZYXsjuCIOC1aUNw18AeqKkzYeGHycgtrZIsz86TuUjNLoOrSo4VDVeFiOzVY+EBEAQg8UoJskuk+7kj+8byQnZJIZfh3bmjENKz8RHqZEkmz9JV1+FvX18AAPzu/gHw9XDq8gxEXSmguwvG9/cGAHyWwqsvZBksL2S33BtWofZxVyOjoBzPbDmJui5+hPpfCRdRUlmLfj1cMT86uEtfm0gqsQ0Ddz9LzoXRZF1P/ZF9YHkhu+bfzRkbfz0Gzko5Dl0q7tJHqNPz9fjo6FUAwOvTh0Kl4I8bOYYHBvuiu4sSWn0NDl4skjoO2SH+a0p2b1iABm8/bn6E+pNj2Vh/KNPirymKIl7dcw4mEZgyrCfGD/C2+GsSWQu1Qo6ZowIAcOAuWQbLCzmEBwb74uWHBgMA/rrvAr4+k2/R19tz6jqOZ92Ak1KGlQ2vS+RIGm8dfZtegKJyg8RpyN6wvJDDWDCuD+ZFmSeHW7YtDWk5lnmEusJQj7/uSwcAPHtPf/Tq5myR1yGyZoN6umNEYDfUm0TsTs2VOg7ZGZYXchiCIOCVqYNxz6AeMNSbsOjDE8i50fmPcr7z3SUU6A0I8nLBogl9O/3rE9mKOQ1XXz49kWN1y3WQbWN5IYeikMvwztzRCPXzQHFFLZ7cfAK66s57hPpyYUXTsgSvThsMJ6W80742ka2ZOtwPzko5MosqkXKtVOo4ZEdYXsjhuKkV2DQ/HL4ealwqrOi0R6hFUcRre86h3iTivhAf3Bvi2wlpiWyXu5MSU4f7AeDAXepcLC/kkPw05keoXVRyHL5cjJc/P9vhy9rfnNPi8OViqBQyvDKNg3SJgP8N3P3qdD7KJZgokuwTyws5rKG9NHjn8VGQCeZ78u8fvPNHqKtrjfjzV+ZBuksn9kWQl2tnxSSyaWFB3dG3hyuq64z46rRln/Ijx8HyQg7tvlBfvDLVfJXkb19fwL47fIR67Y+XkVdWjV7dnPH03f07MyKRTRMEoWngLm8dUWdheSGHN39cMOZH9wEAPL8tDSez2zew8FpJJd5ruGrz8tRQOKs4SJfo5x4ZHQCFTEBaThkytOVSxyE7YNHyUlpairi4OGg0Gmg0GsTFxaGs7OZza9TV1eHFF1/EsGHD4OrqCn9/f8ybNw/Xr1+3ZEwivDx1MO4P9YGh3oTFHya36xHqVV+eR229CRMGeGPSkJ4WTElkm7zd1Lgv1AcAr75Q57BoeZk7dy7S0tKwf/9+7N+/H2lpaYiLi7vp8VVVVTh58iRefvllnDx5Ert27cLFixcxffp0S8Ykglwm4N9zRmGIvwdKKmuxoI2PUH+XXoDvLhRCKRfw6rQhEAShC9IS2Z45Y3oDAHal5sJQb5Q4Ddk6QbTQzEHp6ekYPHgwkpKSEBkZCQBISkpCVFQULly4gEGDBrXp65w4cQIRERG4du0aevfu3eLzBoMBBsP/pp7W6/UIDAyETqeDh4dH53wz5DC0uhrM+M8RaPU1iO7nhc0LIm66oGJNnRGTVh/EtZIqLLmrL1ZMDu3itES2w2gSMe5v30Orr8G7c0dh6nB/qSORldHr9dBoNG16/7bYlZejR49Co9E0FRcAGDt2LDQaDRITE9v8dXQ6HQRBQLdu3Vr9fHx8fNNtKY1Gg8DAwA5nJ8fVU+OETfPHwFUlR+KVEvzp8zM3fYR6w6FMXCupgq+HGr+9d0AXJyWyLXKZgMfCuVgjdQ6LlRetVgsfH58W+318fKDVatv0NWpqavDSSy9h7ty5N21hK1asgE6na9pycvhDQR0z2N8D784dDZkAbE/OxZofr7Q4Jq+sGu/+cBkA8McpoXBTK7o6JpHNeSzM/Mvl4cvFyC3t/KU5yHG0u7y89tprEAThlltycjIAtHr/XxTFNo0LqKurw5w5c2AymbBmzZqbHqdWq+Hh4dFsI+qoe0J88Nr0IQCA//smA1+dbj5o/I2vzqOmzoSIYE9MH8HL30Rt0dvLBdH9vCCKwGfJXKyR7ly7f1189tlnMWfOnFse06dPH5w+fRoFBQUtPldUVARf31tPm15XV4fZs2cjKysL33//PQsJSWJeVB9cLa7CpiNZWL79FPw0zggL6o5Dl4rw9Vkt5DIBr0/nIF2i9ogdE4jEKyX4LDkHz903AHIZf36o/dpdXry9veHt7X3b46KioqDT6XD8+HFEREQAAI4dOwadTofo6OibntdYXC5duoQffvgBXl5e7Y1I1GlWPhSK7BtV+Da9AIs/Ssb2JVF4bc85AEDc2CCE+rFYE7XHpCE9oXFW4rquBocvF+OugT2kjkQ2yGJjXkJDQ/Hggw9i8eLFSEpKQlJSEhYvXoypU6c2e9IoJCQEu3fvBgDU19dj1qxZSE5OxpYtW2A0GqHVaqHValFbW2upqEQ3JZcJePvxkRjaywM3Kmsx7Z3DuFJUCW83FZ5/YKDU8YhsjpNSjhkjzbdat3PgLt0hi87zsmXLFgwbNgwxMTGIiYnB8OHD8fHHHzc7JiMjAzqdDgCQm5uLPXv2IDc3FyNHjoSfn1/T1p4nlIg6k4tKgY2/HgM/jROq68zzU7z4YAg0zkqJkxHZptiGOV8OnNeipMJwm6OJWrLYPC9Sac9z4kTtkZ6vxxMbjmGwvwc+XBABGe/VE92xae8cxpk8Hf70UCgWTegrdRyyAlYxzwuRvQn188CxP96Hj55kcSHqqNiGxRq3J+fcdC4loptheSFqB4VcxqeLiDrB9JH+cFLKcLGgAqk5N1/zjqg1LC9ERNTlPJyUmDLUDwAH7lL7sbwQEZEkGm8dfXnqOioN9RKnIVvC8kJERJKICPZEsLcrKmuN2Hs6X+o4ZENYXoiISBKC8LPFGpN564jajuWFiIgkM2t0AOQyASnXSnG5sFzqOGQjWF6IiEgyPh5OuGeQDwBgGwfuUhuxvBARkaTmNAzc3XUyD7X1JonTkC1geSEiIkndPagHfNzVKKmsxXfpBVLHIRvA8kJERJJSyGV4NIwDd6ntWF6IiEhys8PNt45+uliE62XVEqcha8fyQkREkgv2dkVksCdEEdiRkit1HLJyLC9ERGQVfr5Yo8nExRrp5lheiIjIKkwe6gd3JwVyS6uReKVE6jhkxVheiIjIKjir5Hh4pD8ADtylW2N5ISIiqzFnTG8AwDdntSitrJU4DVkrlhciIrIaQ3tpMNjPA7VGEz5Py5M6DlkplhciIrIqjQN3t53IgShy4C61xPJCRERWZcbIXlApZLigLcfpXJ3UccgKsbwQEZFV0bgoMXloTwAcuEutY3khIiKrE9sw4+6XaddRVVsvcRqyNiwvRERkdcb29UJvTxeUG+qx74xW6jhkZVheiIjI6shkAmaHmxdr3H6Ct46oOZYXIiKySrPCAiETgONXb+BKUYXUcciKsLwQEZFV6qlxwt2DfACY1zsiasTyQkREVmt2w8DdnSl5qDOaJE5D1oLlhYiIrNZ9oT7wdlOhuMKA7y8USh2HrATLCxERWS2lXIZHR3PgLjXH8kJERFbtsYZbRz9kFEKrq5E4DVkDlhciIrJq/X3cMKZPd5hEYOfJXKnjkBVgeSEiIqvXOHB3e3IOTCYu1ujoWF6IiMjqPTTcD25qBa6VVCEpq0TqOCQxlhciIrJ6LioFpo3wB8CBu2Th8lJaWoq4uDhoNBpoNBrExcWhrKyszecvWbIEgiBg9erVFkxJRES2IHaM+dbR12e10FXVSZyGpGTR8jJ37lykpaVh//792L9/P9LS0hAXF9emcz///HMcO3YM/v7+loxIREQ2YkSABiE93WGoN+GLU3lSxyEJWay8pKenY//+/diwYQOioqIQFRWF9evX46uvvkJGRsYtz83Ly8Ozzz6LLVu2QKlU3vJYg8EAvV7fbCMiIvsjCELTwN1tvHXk0CxWXo4ePQqNRoPIyMimfWPHjoVGo0FiYuJNzzOZTIiLi8MLL7yAIUOG3PZ14uPjm25LaTQaBAYGdkp+IiKyPjNH9YJKLsO563qczdNJHYckYrHyotVq4ePj02K/j48PtFrtTc/7+9//DoVCgeeee65Nr7NixQrodLqmLSeHbZyIyF51d1UhZogvAF59cWTtLi+vvfYaBEG45ZacnAzAfInvl0RRbHU/AKSkpODf//43Nm/efNNjfkmtVsPDw6PZRkRE9qtx4O7naXmoqTNKnIakoGjvCc8++yzmzJlzy2P69OmD06dPo6CgoMXnioqK4Ovr2+p5hw4dQmFhIXr37t20z2g04ve//z1Wr16Nq1evtjcuERHZmXH9vNGrmzPyyqrx9dl8zBwVIHUk6mLtLi/e3t7w9va+7XFRUVHQ6XQ4fvw4IiIiAADHjh2DTqdDdHR0q+fExcXh/vvvb7Zv0qRJiIuLw4IFC9oblYiI7JBMZh64+69vL2LbiRyWFwdksTEvoaGhePDBB7F48WIkJSUhKSkJixcvxtSpUzFo0KCm40JCQrB7924AgJeXF4YOHdpsUyqV6NmzZ7NziIjIsc0KD4AgAEmZN3C1uFLqONTFLDrPy5YtWzBs2DDExMQgJiYGw4cPx8cff9zsmIyMDOh0HDFORERt16ubMyYO6AHAvN4RORZBFEW7WuFKr9dDo9FAp9Nx8C4RkR3bdyYfv9lyEj7uaiS+dC8Ucq54Y8va8/7N/6eJiMgm3R/qC09XFQrLDfgxo0jqONSFWF6IiMgmqRQyPDKqFwBgG28dORSWFyIislmNc758f6EQheU1EqehrsLyQkRENmuArztG9+4Go0nEzhQu1ugoWF6IiMimNV59+Sw5B3b2DArdBMsLERHZtIeG+8NFJUdmcSVOXC2VOg51AZYXIiKyaW5qBaYN9wcAfHoiW+I01BVYXoiIyObNbrh1tO9MPvQ1dRKnIUtjeSEiIps3unc39PdxQ02dCXvSrksdhyyM5YWIiGyeIAiY03D1hcsF2D+WFyIisgszR/WCUi7gdK4O56/rpY5DFsTyQkREdsHLTY0HBvsC4NUXe8fyQkREdmN2uPnW0e7UPNTUGSVOQ5bC8kJERHZjwoAe8Nc4QVddhwPnC6SOQxbC8kJERHZDLhMwq+HqyzbO+WK3WF6IiMiuPBYWAEEAjlwuQc6NKqnjkAWwvBARkV0J9HTBuH7eADhw116xvBARkd1pXKxxR0oujCYu1mhvWF6IiMjuxAzxRTcXJfJ1NTh4qUjqONTJWF6IiMjuqBVyzBzVCwCw7ThvHdkblhciIrJLjbeOvk0vQHGFQeI01JlYXoiIyC6F9PTAiAAN6k0idp/MkzoOdSKWFyIisluxY3oDAD49kQ1R5MBde8HyQkREdmvaCD84K+W4UlSJk9mlUsehTsLyQkREdsvdSYkpw/wAAJ9y4K7dYHkhIiK7NifCPHB375l8VBjqJU5DnYHlhYiI7Fp4UHf07eGKqlojvjp1Xeo41AlYXoiIyK4JgoDYhsUaPz3BW0f2gOWFiIjs3iOjA6CQCUjLKUOGtlzqONRBLC9ERGT3erircW+IDwBgG6++2DyWFyIicgiNA3d3p+bCUG+UOA11BMsLERE5hIkDesDXQ43Sqjp8e75Q6jjUASwvRETkEBRyGWaFBQAwz7hLtovlhYiIHMbshqeODl8uRm5plcRp6E5ZtLyUlpYiLi4OGo0GGo0GcXFxKCsru+156enpmD59OjQaDdzd3TF27FhkZ7MlExFRxwR5uSKqrxdEEdiRkit1HLpDFi0vc+fORVpaGvbv34/9+/cjLS0NcXFxtzznypUrGD9+PEJCQvDjjz/i1KlTePnll+Hk5GTJqERE5CAaB+5+lpwLo4mLNdoiQbTQMpvp6ekYPHgwkpKSEBkZCQBISkpCVFQULly4gEGDBrV63pw5c6BUKvHxxx+36XUMBgMMBkPTx3q9HoGBgdDpdPDw8Oj4N0JERHalps6IiL98C31NPT56MgITB/aQOhLB/P6t0Wja9P5tsSsvR48ehUajaSouADB27FhoNBokJia2eo7JZMLevXsxcOBATJo0CT4+PoiMjMTnn39+09eJj49vui2l0WgQGBjY6d8LERHZDyelHDNG9QLAOV9slcXKi1arhY+PT4v9Pj4+0Gq1rZ5TWFiIiooK/O1vf8ODDz6IAwcOYObMmXjkkUfw008/tXrOihUroNPpmracHP5FJCKiW4sdY/5F98B5LW5U1kqchtqr3eXltddegyAIt9ySk5MBmNeT+CVRFFvdD5ivvADAww8/jOeffx4jR47ESy+9hKlTp+K9995r9Ry1Wg0PD49mGxER0a0M8ddgaC8P1BlF7E7NkzoOtZOivSc8++yzmDNnzi2P6dOnD06fPo2CgoIWnysqKoKvr2+r53l7e0OhUGDw4MHN9oeGhuLw4cPtjUpERHRTseGBOJt3DttOZOPJcX1u+os1WZ92lxdvb294e3vf9rioqCjodDocP34cERERAIBjx45Bp9MhOjq61XNUKhXGjBmDjIyMZvsvXryIoKCg9kYlIiK6qekje+GNvem4WFCBtJwyjOrdXepI1EYWG/MSGhqKBx98EIsXL0ZSUhKSkpKwePFiTJ06tdmTRiEhIdi9e3fTxy+88AK2bduG9evX4/Lly3j33Xfx5Zdf4je/+Y2lohIRkQPSOCsxZZgfAGB7MsdL2hKLzvOyZcsWDBs2DDExMYiJicHw4cNbPAKdkZEBnU7X9PHMmTPx3nvv4c0338SwYcOwYcMG7Ny5E+PHj7dkVCIickCNA3f3pF1HpaFe4jTUVhab50Uq7XlOnIiIHJsoirjnHz/iakkV3pw1vGn5AOp6VjHPCxERkbUTBAGPNRQWzvliO1heiIjIoc0KC4BcJiDlWikuF5ZLHYfagOWFiIgcmq+HE+4ZZF4iYHsyF2u0BSwvRETk8BrHuuxMyUVtvUniNHQ7LC9EROTw7gnxQQ93NUoqa/H9hZYTrJJ1YXkhIiKHp5TL8OjoAAAcuGsLWF6IiIjwvzlffrpYhHxdtcRp6FZYXoiIiAAEe7siItgTJhHYwYG7Vo3lhYiIqEFs45wvvNVWigAADXBJREFUyTkwmexqDle7wvJCRETUYMowP7irFcgtrcbRzBKp49BNsLwQERE1cFbJMX2kPwAO3LVmLC9EREQ/0zhwd/85LcqqaiVOQ61heSEiIvqZYb00CPXzQG29CZ+n5kkdh1rB8kJERPQzgiAgNtw858unJ3Igihy4a21YXoiIiH5hxqheUClkuKAtx5k8ndRx6BdYXoiIiH6hm4sKDw7pCYADd60RywsREVErGgfu7km7jupao8Rp6OdYXoiIiFoR1dcLgZ7OKDfUY9+ZfKnj0M+wvBAREbVCJhMwO+x/M+6S9WB5ISIiuolZ4QGQCcDxrBvILKqQOg41YHkhIiK6CT+NM+4a2AMAsJ2LNVoNlhciIqJbaBy4uyMlF3VGk8RpCAAUUgcgIiKyZveG+MLbTYXiCgN+uFCImIZHqO2RySRCV12HG1W1uFF5880kivh4YaRkOVleiIiIbkGlkOGR0QFYdzAT25NzbKq8GOqNKK2sQ0mloVn5KK2sRckvCklpVS1Kq+pgNN1+RmG5TIAoihAEoQu+i5ZYXoiIiG5jdngg1h3MxPcXClGgr4Gvh1OXZxBFEfqa+mbFo/HPpVW1KKmoxY1KA25U1eFGpQGllXWoMNTf0Wu5qxXwdFOhu4sKXq4qeP5s6+5q3mcSAbk03YXlhYiI6Hb6+7ghPKg7kq+VYkdKLp65p3+Hv2ad0YTSylrzLZqK2qZbNSUVDWWkoZzcqPzfn+vbcFXkl+Qy4ZYlpPG/TftdVFAprHtILMsLERFRG8weE4jka6XYnpyD39zdr9ktE1EUUVlr/FkJMeBGZd0v/tv8No2+5s6uiriq5M0Kxy9LSHcXFbzcVPB0VcPTRQUPZ4Vkt3cs5f+3d78xTZ0LGMCf0tKCDIrAyugtAmEGcAI6Ol2RRTMNgzDdn8TNzLEuRpfegSJki9N9GDfZ7D7MDyNOkuLCJG6XfdhQtsQi3iHbogxhaySMiy4aIW6MzUmpbAGl7/1wI14GCtys5/XQ55ecpNRzcp732A9P3r6nh+WFiIhoFooyE/CPxm5cuvI7th7qwOgN/60y8vsYxm7M/U6kEA2wcMF/i0fMbUvIrdcLF+gRFqoNwOjUheWFiIhoFiIMOmxY9jf8s70P//r34LT7hIWGIDbCMHlG5H+KR0zErdexEXpEhYdCGzK/ZkWUwPJCREQ0S7sK0rAoZgFCtZqJNSKxEQYsjAhFbIQB4XrOiiiB5YWIiGiWohfo8fc1qbJjBL27ezkxERER0Z+wvBAREZGqsLwQERGRqgS0vFy9ehXFxcUwGo0wGo0oLi7G0NDQHY+5du0aSktLYbFYEB4ejoyMDFRXVwcyJhEREalIQMvLc889B4/HA7fbDbfbDY/Hg+Li4jseU15eDrfbjcOHD6Onpwfl5eXYvn07jh49GsioREREpBIBKy89PT1wu904ePAgbDYbbDYbampq8Pnnn6O3t/e2x50+fRp2ux1r1qxBcnIyXnrpJWRnZ6OjoyNQUYmIiEhFAlZeTp8+DaPRiJUrbz0y++GHH4bRaMSpU6due1xeXh4aGxtx+fJlCCHQ0tKCc+fO4bHHHpt2/9HRUQwPD0/aiIiIaP4KWHkZGBiAyWSa8r7JZMLAwMBtj6uqqsKSJUtgsVig1+tRUFCAAwcOIC8vb9r9nU7nxJoao9GIxMTEv2wMREREdPeZc3mprKyERqO543bzK57pHgQlhLjjA6KqqqrQ1taGxsZGdHZ2Yt++fXj55Zdx4sSJafffvXs3vF7vxNbf3z/XIREREZGKzPkXdktLS7Fp06Y77pOcnIyzZ8/i559/nvJvv/zyC+Lj46c97o8//sCePXvQ0NCAoqIiAEBWVhY8Hg/eeecdrFu3bsoxBoMBBoNhrsMgIiIilZpzeYmLi0NcXNyM+9lsNni9XrS3t2PFihUAgG+++QZerxe5ubnTHnP9+nVcv34dISGTJ4S0Wi38/rk/rZOIiIjmn4CtecnIyEBBQQG2bduGtrY2tLW1Ydu2bXj88ceRlpY2sV96ejoaGhoAAFFRUVi9ejVeffVVnDx5EhcvXsQHH3yAuro6PPXUU4GKSkRERCoS0Aczfvjhh9ixYwfy8/MBABs2bMD+/fsn7dPb2wuv1zvxd319PXbv3o3Nmzfjt99+Q1JSEt566y04HI5ARiUiIiKV0AghhOwQfyWv14vo6Gj09/cjKipKdhwiIiKaheHhYSQmJmJoaAhGo/GO+wZ05kUGn88HALxlmoiISIV8Pt+M5WXezbz4/X78+OOPiIyMvOMt2f+Pm60wWGd1gn38AK9BsI8f4DUI9vEDvAaBGr8QAj6fD2azecqNO38272ZeQkJCYLFYAnqOqKiooPzA3hTs4wd4DYJ9/ACvQbCPH+A1CMT4Z5pxuSmgD2YkIiIi+quxvBAREZGqaCsrKytlh1ATrVaLNWvWQKebd9+4zUqwjx/gNQj28QO8BsE+foDXQPb4592CXSIiIprf+LURERERqQrLCxEREakKywsRERGpCssLERERqQrLCxEREakKy8ssHThwACkpKQgLC0NOTg6++uor2ZEU9eWXX2L9+vUwm83QaDQ4cuSI7EiKcTqdeOihhxAZGQmTyYQnn3wSvb29smMpqrq6GllZWRO/qGmz2XDs2DHZsaRxOp3QaDTYuXOn7CiKqayshEajmbTdd999smMp6vLly3j++ecRGxuLBQsWYNmyZejs7JQdSzHJyclTPgMajQYlJSWKZ2F5mYWPP/4YO3fuxOuvv47vvvsOjzzyCAoLC9HX1yc7mmJGRkaQnZ2N/fv3y46iuNbWVpSUlKCtrQ3Nzc24ceMG8vPzMTIyIjuaYiwWC95++210dHSgo6MDjz76KJ544gl0d3fLjqa4M2fOwOVyISsrS3YUxT3wwAP46aefJrauri7ZkRRz9epVrFq1CqGhoTh27Bi+//577Nu3D9HR0bKjKebMmTOT/v+bm5sBABs3blQ+jKAZrVixQjgcjknvpaeni9dee01SIrkAiIaGBtkxpBkcHBQARGtrq+woUi1cuFAcPHhQdgxF+Xw+sXjxYtHc3CxWr14tysrKZEdSzBtvvCGys7Nlx5Bm165dIi8vT3aMu0pZWZlITU0Vfr9f8XNz5mUGY2Nj6OzsRH5+/qT38/PzcerUKUmpSCav1wsAiImJkZxEjvHxcdTX12NkZAQ2m012HEWVlJSgqKgI69atkx1FivPnz8NsNiMlJQWbNm3ChQsXZEdSTGNjI6xWKzZu3AiTyYTly5ejpqZGdixpxsbGcPjwYWzZsgUajUbx87O8zODXX3/F+Pg44uPjJ70fHx+PgYEBSalIFiEEKioqkJeXh6VLl8qOo6iuri7cc889MBgMcDgcaGhowJIlS2THUkx9fT2+/fZbOJ1O2VGkWLlyJerq6tDU1ISamhoMDAwgNzcXV65ckR1NERcuXEB1dTUWL16MpqYmOBwO7NixA3V1dbKjSXHkyBEMDQ3hxRdflHL+4Hwow//hz81SCCGlbZJcpaWlOHv2LL7++mvZURSXlpYGj8eDoaEhfPLJJ7Db7WhtbQ2KAtPf34+ysjIcP34cYWFhsuNIUVhYOPE6MzMTNpsNqampOHToECoqKiQmU4bf74fVasXevXsBAMuXL0d3dzeqq6vxwgsvSE6nvPfffx+FhYUwm81Szs+ZlxnExcVBq9VOmWUZHBycMhtD89v27dvR2NiIlpYWWCwW2XEUp9frcf/998NqtcLpdCI7Oxvvvvuu7FiK6OzsxODgIHJycqDT6aDT6dDa2oqqqirodDqMj4/Ljqi4iIgIZGZm4vz587KjKCIhIWFKUc/IyAiqGzduunTpEk6cOIGtW7dKy8DyMgO9Xo+cnJyJVdU3NTc3Izc3V1IqUpIQAqWlpfj000/xxRdfICUlRXaku4IQAqOjo7JjKGLt2rXo6uqCx+OZ2KxWKzZv3gyPxwOtVis7ouJGR0fR09ODhIQE2VEUsWrVqik/kXDu3DkkJSVJSiRPbW0tTCYTioqKpGXg10azUFFRgeLiYlitVthsNrhcLvT19cHhcMiOpphr167hhx9+mPj74sWL8Hg8iImJwaJFiyQmC7ySkhJ89NFHOHr0KCIjIydm4YxGI8LDwyWnU8aePXtQWFiIxMRE+Hw+1NfX4+TJk3C73bKjKSIyMnLKGqeIiAjExsYGzdqnV155BevXr8eiRYswODiIN998E8PDw7Db7bKjKaK8vBy5ubnYu3cvnnnmGbS3t8PlcsHlcsmOpii/34/a2lrY7XbodBIrhOL3N6nUe++9J5KSkoRerxcPPvhg0N0m29LSIgBM2ex2u+xoATfduAGI2tpa2dEUs2XLlonP/7333ivWrl0rjh8/LjuWVMF2q/Szzz4rEhISRGhoqDCbzeLpp58W3d3dsmMp6rPPPhNLly4VBoNBpKenC5fLJTuS4pqamgQA0dvbKzWHRggh5NQmIiIiornjmhciIiJSFZYXIiIiUhWWFyIiIlIVlhciIiJSFZYXIiIiUhWWFyIiIlIVlhciIiJSFZYXIiIiUhWWFyIiIlIVlhciIiJSFZYXIiIiUpX/AJ0PFJgxCR1+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ridge.coef_)\n",
    "plt.plot(ridge.coef_.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Change the $\\lambda$ value of your parameter to 1000. Retrain your model, recompute the prediction error. What do you observe ? \n",
    "\n",
    "Be careful, in `sklearn` $\\lambda$ parameter is denoted as $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge1000=Ridge(alpha=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1000)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge1000.fit(X_train_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5856390756536678"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge1000.score(X_train_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4773159995334937"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train1000=ridge1000.predict(X_train_norm)\n",
    "mean_absolute_error(y_train_norm,y_pred_train1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5691545592810134"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge1000.score(X_test_norm,y_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4804942252194657"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test1000=ridge1000.predict(X_test_norm)\n",
    "mean_absolute_error(y_test_norm,y_pred_test1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean absolute errors are increased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now check your model parameters and compared them to your model when $\\lambda = 1$. What do you conclude ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When lambda = 1\n",
      "Mean absolute error: 0.461470085494359\n",
      "When lambda = 1000\n",
      "Mean absolute error: 0.4804942252194657\n"
     ]
    }
   ],
   "source": [
    "print(\"When lambda = 1\")\n",
    "print(f\"Mean absolute error: {mean_absolute_error(y_test_norm,y_pred_test)}\")\n",
    "print(\"When lambda = 1000\")\n",
    "print(f\"Mean absolute error: {mean_absolute_error(y_test_norm,y_pred_test1000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1000,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': 'deprecated',\n",
       " 'positive': False,\n",
       " 'random_state': None,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge1000.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': 'deprecated',\n",
       " 'positive': False,\n",
       " 'random_state': None,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Only alpha is changed<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best $\\lambda$\n",
    "Since $\\lambda$ may have a strong effect on your model performance, we need to find the best possible value according to the dataset we work on. \n",
    "1. Try different values for $\\lambda$ and evaluate the performances. Use a log scale of values between $10^{-3}$ to $10^{4}$ , i.e. `alphas = np.logspace(-3,4,10)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mae_train = []\n",
    "mae_test = []\n",
    "coefs = []\n",
    "alphas = np.logspace(-3,4,10)\n",
    "for alpha in alphas:\n",
    "    ridge_alpha = Ridge(alpha=alpha)\n",
    "    ridge_alpha.fit(X_train_norm, y_train_norm)\n",
    "    y_pred_train=ridge_alpha.predict(X_train_norm)\n",
    "    mae_train.append(mean_absolute_error(y_train_norm,y_pred_train))\n",
    "    y_pred_test = ridge_alpha.predict(X_test_norm)\n",
    "    mae_test.append(mean_absolute_error(y_test_norm,y_pred_test))\n",
    "    coefs.append(ridge_alpha.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-03, 5.99484250e-03, 3.59381366e-02, 2.15443469e-01,\n",
       "       1.29154967e+00, 7.74263683e+00, 4.64158883e+01, 2.78255940e+02,\n",
       "       1.66810054e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.459565464120599,\n",
       " 0.45956543698671787,\n",
       " 0.45956527433646416,\n",
       " 0.4595643067379952,\n",
       " 0.4595586137604112,\n",
       " 0.45952746131604144,\n",
       " 0.4594526176446621,\n",
       " 0.4620429423197097,\n",
       " 0.4906166530171619,\n",
       " 0.5792939155406569]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46146867344834813,\n",
       " 0.4614686804736128,\n",
       " 0.46146872259630656,\n",
       " 0.46146897537881093,\n",
       " 0.46147050021243247,\n",
       " 0.46148222955100726,\n",
       " 0.46165483192845636,\n",
       " 0.46478851179089054,\n",
       " 0.4941079619562992,\n",
       " 0.5836991861394631]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.72993777,  0.10252171, -0.23016034,  0.25052117, -0.00792302,\n",
       "         -0.02394053, -0.76030852, -0.737354  ]]),\n",
       " array([[ 0.72993765,  0.10252212, -0.2301597 ,  0.25052026, -0.00792286,\n",
       "         -0.02394058, -0.76030457, -0.73735002]]),\n",
       " array([[ 0.72993692,  0.10252458, -0.23015589,  0.25051483, -0.00792194,\n",
       "         -0.02394089, -0.76028088, -0.73732617]]),\n",
       " array([[ 0.72993252,  0.10253933, -0.230133  ,  0.25048223, -0.00791639,\n",
       "         -0.02394275, -0.7601389 , -0.73718318]]),\n",
       " array([[ 0.72990595,  0.10262758, -0.22999562,  0.25028678, -0.00788319,\n",
       "         -0.02395384, -0.75928912, -0.73632735]]),\n",
       " array([[ 0.72973888,  0.10315131, -0.22916488,  0.24911271, -0.00768601,\n",
       "         -0.02401969, -0.75424303, -0.73124444]]),\n",
       " array([[ 0.72848476,  0.10610868, -0.22396651,  0.24201689, -0.00656788,\n",
       "         -0.02439143, -0.72562089, -0.70238436]]),\n",
       " array([[ 0.71577018,  0.11892099, -0.19019934,  0.20080506, -0.00161599,\n",
       "         -0.02598945, -0.59653598, -0.57161382]]),\n",
       " array([[ 0.6293716 ,  0.13503067, -0.06265164,  0.06486611,  0.00580506,\n",
       "         -0.02752004, -0.31417357, -0.2826383 ]]),\n",
       " array([[ 0.39368522,  0.08719865,  0.03726356, -0.02618745, -0.00198739,\n",
       "         -0.01840127, -0.10663749, -0.07429807]])]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. What is the best value for $\\lambda$ ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">last one is the best : alpha = 10000.0<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Plot the different values of $\\mathbf{w}$ parameters for each $\\lambda$ values. Discuss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in coefs:\n",
    "    plt.plot(i.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "To find the best $\\lambda$ value, we should use only the train set. To evaluate the performance on unseen data without using test set, we will simulate it by splitting the train set into a new train set and a validation set used to evaluate the performance according to $\\lambda$. A good practice is to repeat this split to have a better estimation of the performance. \n",
    "\n",
    "`sklearn` provide a class `GridSearchCV` in `sklearn.model_selection` which implements this protocol.\n",
    "1. Check the documentation of `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`\n",
      " |      to see how to design a custom selection strategy using a callable\n",
      " |      via `refit`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels. This is present only if ``refit`` is specified and\n",
      " |      the underlying estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `n_features_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `feature_names_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Result of the decision function for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the `fit` method of the estimator.\n",
      " |      \n",
      " |          If a fit parameter is an array-like whose length is equal to\n",
      " |          `num_samples` then it will be split across CV groups along with `X`\n",
      " |          and `y`. For example, the :term:`sample_weight` parameter is split\n",
      " |          because `len(sample_weights) = len(X)`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Instance of fitted estimator.\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Result of the `inverse_transform` function for `Xt` based on the\n",
      " |          estimator with the best found parameters.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          The predicted labels or values for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class log-probabilities for `X` based on the estimator\n",
      " |          with the best found parameters. The order of the classes\n",
      " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class probabilities for `X` based on the estimator with\n",
      " |          the best found parameters. The order of the classes corresponds\n",
      " |          to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Return the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          The score defined by ``scoring`` if provided, and the\n",
      " |          ``best_estimator_.score`` method otherwise.\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |          The ``best_estimator_.score_samples`` method.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          `X` transformed in the new space based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |      Class labels.\n",
      " |      \n",
      " |      Only available when `refit=True` and the estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |      \n",
      " |      Only available when `refit=True`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the parameters you want to test during your cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    \"alpha\":np.logspace(-3,4,10),\n",
    "    \"fit_intercept\":(True,False),\n",
    "    \"copy_X\": (True, False),\n",
    "    \"positive\":(True, False),\n",
    "    \"solver\": (\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\", \"lbfgs\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run your grid search cross validation and print the MAE for test and train set. What is the  best value of $\\lambda$ according to your Cross Validation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GridSearchCV(Ridge(),parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elnur/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "1400 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 1130, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 813, in fit\n",
      "    raise ValueError(\n",
      "ValueError: solver='svd' does not support positive fitting. Please set the solver to 'auto' or 'lbfgs', or set `positive=False`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 1130, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 813, in fit\n",
      "    raise ValueError(\n",
      "ValueError: solver='cholesky' does not support positive fitting. Please set the solver to 'auto' or 'lbfgs', or set `positive=False`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 1130, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 813, in fit\n",
      "    raise ValueError(\n",
      "ValueError: solver='lsqr' does not support positive fitting. Please set the solver to 'auto' or 'lbfgs', or set `positive=False`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 1130, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 813, in fit\n",
      "    raise ValueError(\n",
      "ValueError: solver='sparse_cg' does not support positive fitting. Please set the solver to 'auto' or 'lbfgs', or set `positive=False`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 1130, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 813, in fit\n",
      "    raise ValueError(\n",
      "ValueError: solver='sag' does not support positive fitting. Please set the solver to 'auto' or 'lbfgs', or set `positive=False`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 1130, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 813, in fit\n",
      "    raise ValueError(\n",
      "ValueError: solver='saga' does not support positive fitting. Please set the solver to 'auto' or 'lbfgs', or set `positive=False`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 1130, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\", line 806, in fit\n",
      "    raise ValueError(\n",
      "ValueError: 'lbfgs' solver can be used only when positive=True. Please use another solver.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/elnur/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.51614955        nan        nan        nan        nan        nan\n",
      "        nan 0.51614955 0.60641706 0.60641706 0.60641706 0.60641706\n",
      " 0.60641706 0.60637502 0.6063503         nan 0.51615621        nan\n",
      "        nan        nan        nan        nan        nan 0.51615621\n",
      " 0.60644749 0.60644749 0.60644749 0.60644749 0.60644749 0.60640294\n",
      " 0.60637877        nan 0.51614955        nan        nan        nan\n",
      "        nan        nan        nan 0.51614955 0.60641706 0.60641706\n",
      " 0.60641706 0.60641706 0.60641706 0.60637275 0.60634905        nan\n",
      " 0.51615621        nan        nan        nan        nan        nan\n",
      "        nan 0.51615621 0.60644749 0.60644749 0.60644749 0.60644749\n",
      " 0.60644749 0.60639997 0.60638368        nan 0.51614956        nan\n",
      "        nan        nan        nan        nan        nan 0.51614956\n",
      " 0.60641711 0.60641711 0.60641711 0.60641711 0.60641711 0.60637129\n",
      " 0.60635017        nan 0.51615621        nan        nan        nan\n",
      "        nan        nan        nan 0.51615621 0.60644753 0.60644753\n",
      " 0.60644753 0.60644753 0.60644753 0.60640252 0.60638072        nan\n",
      " 0.51614956        nan        nan        nan        nan        nan\n",
      "        nan 0.51614956 0.60641711 0.60641711 0.60641711 0.60641711\n",
      " 0.60641711 0.60637138 0.60635012        nan 0.51615621        nan\n",
      "        nan        nan        nan        nan        nan 0.51615621\n",
      " 0.60644753 0.60644753 0.60644753 0.60644753 0.60644753 0.60640409\n",
      " 0.60638359        nan 0.51614956        nan        nan        nan\n",
      "        nan        nan        nan 0.51614956 0.60641738 0.60641738\n",
      " 0.60641738 0.60641738 0.60641738 0.60637181 0.60635124        nan\n",
      " 0.51615622        nan        nan        nan        nan        nan\n",
      "        nan 0.51615622 0.6064478  0.6064478  0.6064478  0.6064478\n",
      " 0.6064478  0.60640321 0.6063808         nan 0.51614956        nan\n",
      "        nan        nan        nan        nan        nan 0.51614956\n",
      " 0.60641738 0.60641738 0.60641738 0.60641738 0.60641738 0.60637136\n",
      " 0.60635494        nan 0.51615622        nan        nan        nan\n",
      "        nan        nan        nan 0.51615622 0.6064478  0.6064478\n",
      " 0.6064478  0.6064478  0.6064478  0.60640384 0.60638536        nan\n",
      " 0.51614959        nan        nan        nan        nan        nan\n",
      "        nan 0.51614959 0.60641898 0.60641898 0.60641898 0.60641898\n",
      " 0.60641898 0.60637424 0.60634906        nan 0.51615625        nan\n",
      "        nan        nan        nan        nan        nan 0.51615625\n",
      " 0.6064494  0.6064494  0.6064494  0.6064494  0.6064494  0.60640139\n",
      " 0.60638685        nan 0.51614959        nan        nan        nan\n",
      "        nan        nan        nan 0.51614959 0.60641898 0.60641898\n",
      " 0.60641898 0.60641898 0.60641898 0.6063774  0.60634939        nan\n",
      " 0.51615625        nan        nan        nan        nan        nan\n",
      "        nan 0.51615625 0.6064494  0.6064494  0.6064494  0.6064494\n",
      " 0.6064494  0.60640535 0.60638119        nan 0.51614978        nan\n",
      "        nan        nan        nan        nan        nan 0.51614978\n",
      " 0.60642839 0.60642839 0.60642839 0.60642839 0.60642839 0.60638172\n",
      " 0.60636235        nan 0.51615644        nan        nan        nan\n",
      "        nan        nan        nan 0.51615644 0.60645875 0.60645875\n",
      " 0.60645875 0.60645875 0.60645875 0.60641125 0.60638874        nan\n",
      " 0.51614978        nan        nan        nan        nan        nan\n",
      "        nan 0.51614978 0.60642839 0.60642839 0.60642839 0.60642839\n",
      " 0.60642839 0.60638306 0.60636158        nan 0.51615644        nan\n",
      "        nan        nan        nan        nan        nan 0.51615644\n",
      " 0.60645875 0.60645875 0.60645875 0.60645875 0.60645875 0.60640976\n",
      " 0.60638544        nan 0.51615067        nan        nan        nan\n",
      "        nan        nan        nan 0.51615067 0.60647723 0.60647723\n",
      " 0.60647723 0.60647723 0.60647723 0.60642475 0.60638509        nan\n",
      " 0.5161573         nan        nan        nan        nan        nan\n",
      "        nan 0.5161573  0.60650727 0.60650727 0.60650727 0.60650727\n",
      " 0.60650727 0.60645524 0.60641615        nan 0.51615067        nan\n",
      "        nan        nan        nan        nan        nan 0.51615067\n",
      " 0.60647723 0.60647723 0.60647723 0.60647723 0.60647723 0.60641708\n",
      " 0.60638688        nan 0.5161573         nan        nan        nan\n",
      "        nan        nan        nan 0.5161573  0.60650727 0.60650727\n",
      " 0.60650727 0.60650727 0.60650727 0.60645284 0.60641663        nan\n",
      " 0.5161473         nan        nan        nan        nan        nan\n",
      "        nan 0.5161473  0.60652695 0.60652695 0.60652695 0.60652695\n",
      " 0.60652695 0.60643054 0.60632563        nan 0.5161538         nan\n",
      "        nan        nan        nan        nan        nan 0.5161538\n",
      " 0.60655519 0.60655519 0.60655519 0.60655519 0.60655519 0.60645754\n",
      " 0.60635751        nan 0.5161473         nan        nan        nan\n",
      "        nan        nan        nan 0.5161473  0.60652695 0.60652695\n",
      " 0.60652695 0.60652695 0.60652695 0.60643066 0.60632727        nan\n",
      " 0.5161538         nan        nan        nan        nan        nan\n",
      "        nan 0.5161538  0.60655519 0.60655519 0.60655519 0.60655519\n",
      " 0.60655519 0.60646146 0.60635701        nan 0.51566589        nan\n",
      "        nan        nan        nan        nan        nan 0.51566589\n",
      " 0.60186809 0.60186809 0.60186809 0.60186809 0.60186809 0.60165837\n",
      " 0.60129573        nan 0.51567142        nan        nan        nan\n",
      "        nan        nan        nan 0.51567142 0.6018888  0.6018888\n",
      " 0.6018888  0.6018888  0.6018888  0.60167565 0.60133773        nan\n",
      " 0.51566589        nan        nan        nan        nan        nan\n",
      "        nan 0.51566589 0.60186809 0.60186809 0.60186809 0.60186809\n",
      " 0.60186809 0.60166176 0.6013148         nan 0.51567142        nan\n",
      "        nan        nan        nan        nan        nan 0.51567142\n",
      " 0.6018888  0.6018888  0.6018888  0.6018888  0.6018888  0.60169045\n",
      " 0.60132642        nan 0.50605889        nan        nan        nan\n",
      "        nan        nan        nan 0.50605889 0.55810476 0.55810476\n",
      " 0.55810476 0.55809159 0.55810344 0.55797726 0.5573345         nan\n",
      " 0.50606244        nan        nan        nan        nan        nan\n",
      "        nan 0.50606244 0.5581126  0.5581126  0.5581126  0.55809941\n",
      " 0.55811128 0.55803665 0.55734453        nan 0.50605889        nan\n",
      "        nan        nan        nan        nan        nan 0.50605889\n",
      " 0.55810476 0.55810476 0.55810476 0.55809159 0.55810344 0.55790489\n",
      " 0.55734227        nan 0.50606244        nan        nan        nan\n",
      "        nan        nan        nan 0.50606244 0.5581126  0.5581126\n",
      " 0.5581126  0.55809941 0.55811128 0.55803073 0.55736239        nan\n",
      " 0.39106822        nan        nan        nan        nan        nan\n",
      "        nan 0.39106822 0.41194079 0.41194079 0.41194079 0.41194327\n",
      " 0.41194036 0.41199372 0.4120244         nan 0.39107509        nan\n",
      "        nan        nan        nan        nan        nan 0.39107509\n",
      " 0.41194906 0.41194906 0.41194906 0.41195155 0.41194864 0.41197184\n",
      " 0.41203076        nan 0.39106822        nan        nan        nan\n",
      "        nan        nan        nan 0.39106822 0.41194079 0.41194079\n",
      " 0.41194079 0.41194327 0.41194036 0.41193532 0.41200493        nan\n",
      " 0.39107509        nan        nan        nan        nan        nan\n",
      "        nan 0.39107509 0.41194906 0.41194906 0.41194906 0.41195155\n",
      " 0.41194864 0.41195313 0.41203401        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-03, 5.99484250e-03, 3.59381366e-02, 2.15443469e-01,\n",
       "       1.29154967e+00, 7.74263683e+00, 4.64158883e+01, 2.78255940e+02,\n",
       "       1.66810054e+03, 1.00000000e+04]),\n",
       "                         &#x27;copy_X&#x27;: (True, False),\n",
       "                         &#x27;fit_intercept&#x27;: (True, False),\n",
       "                         &#x27;positive&#x27;: (True, False),\n",
       "                         &#x27;solver&#x27;: (&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;, &#x27;lsqr&#x27;,\n",
       "                                    &#x27;sparse_cg&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;, &#x27;lbfgs&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-03, 5.99484250e-03, 3.59381366e-02, 2.15443469e-01,\n",
       "       1.29154967e+00, 7.74263683e+00, 4.64158883e+01, 2.78255940e+02,\n",
       "       1.66810054e+03, 1.00000000e+04]),\n",
       "                         &#x27;copy_X&#x27;: (True, False),\n",
       "                         &#x27;fit_intercept&#x27;: (True, False),\n",
       "                         &#x27;positive&#x27;: (True, False),\n",
       "                         &#x27;solver&#x27;: (&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;, &#x27;lsqr&#x27;,\n",
       "                                    &#x27;sparse_cg&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;, &#x27;lbfgs&#x27;)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={'alpha': array([1.00000000e-03, 5.99484250e-03, 3.59381366e-02, 2.15443469e-01,\n",
       "       1.29154967e+00, 7.74263683e+00, 4.64158883e+01, 2.78255940e+02,\n",
       "       1.66810054e+03, 1.00000000e+04]),\n",
       "                         'copy_X': (True, False),\n",
       "                         'fit_intercept': (True, False),\n",
       "                         'positive': (True, False),\n",
       "                         'solver': ('auto', 'svd', 'cholesky', 'lsqr',\n",
       "                                    'sparse_cg', 'sag', 'saga', 'lbfgs')})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.41588833612782"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_[\"alpha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 0.4594526176446614\n",
      "Test MAE: 0.46165483192845574\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train MAE: {mean_absolute_error(y_train_norm, model.predict(X_train_norm))}\")\n",
    "print(f\"Test MAE: {mean_absolute_error(y_test_norm, model.predict(X_test_norm))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the criterion used by `GridSearchCV` to determine the best $\\lambda$ ? Change it to fit our measure of performance, i.e. the MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV uses these criterions: {'alpha': 46.41588833612782, 'copy_X': True, 'fit_intercept': False, 'positive': False, 'solver': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "print(\"GridSearchCV uses these criterions:\",model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE 0.5208040729092552\n",
      "Test MAE 0.5243277810188491\n"
     ]
    }
   ],
   "source": [
    "ridge_new=Ridge(alpha=50,copy_X=False, fit_intercept=True, positive=True, solver=\"lbfgs\")\n",
    "ridge_new.fit(X_train_norm, y_train_norm)\n",
    "y_pred_train=ridge_new.predict(X_train_norm)\n",
    "print(\"Train MAE\",mean_absolute_error(y_train_norm, y_pred_train))\n",
    "y_pred_test=ridge_new.predict(X_test_norm)\n",
    "print(\"Test MAE\",mean_absolute_error(y_test_norm, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A full model design\n",
    "Despite the choice of $\\lambda$ is made without bias, the performance has been evaluated on only one split of the data. This particular split may be subject to exceptions and may not constitute a good estimation of the predictive ability of your model. The solution here is to repeat splits so as we average the performances of our model over different train and test sets.\n",
    "\n",
    "1. Check the documentation of `ShuffleSplit` class in `sklearn.model_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ShuffleSplit in module sklearn.model_selection._split:\n",
      "\n",
      "class ShuffleSplit(BaseShuffleSplit)\n",
      " |  ShuffleSplit(n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      " |  \n",
      " |  Random permutation cross-validator\n",
      " |  \n",
      " |  Yields indices to split data into training and test sets.\n",
      " |  \n",
      " |  Note: contrary to other cross-validation strategies, random splits\n",
      " |  do not guarantee that all folds will be different, although this is\n",
      " |  still very likely for sizeable datasets.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <ShuffleSplit>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=10\n",
      " |      Number of re-shuffling & splitting iterations.\n",
      " |  \n",
      " |  test_size : float or int, default=None\n",
      " |      If float, should be between 0.0 and 1.0 and represent the proportion\n",
      " |      of the dataset to include in the test split. If int, represents the\n",
      " |      absolute number of test samples. If None, the value is set to the\n",
      " |      complement of the train size. If ``train_size`` is also None, it will\n",
      " |      be set to 0.1.\n",
      " |  \n",
      " |  train_size : float or int, default=None\n",
      " |      If float, should be between 0.0 and 1.0 and represent the\n",
      " |      proportion of the dataset to include in the train split. If\n",
      " |      int, represents the absolute number of train samples. If None,\n",
      " |      the value is automatically set to the complement of the test size.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the randomness of the training and testing indices produced.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import ShuffleSplit\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])\n",
      " |  >>> y = np.array([1, 2, 1, 2, 1, 2])\n",
      " |  >>> rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
      " |  >>> rs.get_n_splits(X)\n",
      " |  5\n",
      " |  >>> print(rs)\n",
      " |  ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)\n",
      " |  >>> for train_index, test_index in rs.split(X):\n",
      " |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  TRAIN: [1 3 0 4] TEST: [5 2]\n",
      " |  TRAIN: [4 0 2 5] TEST: [1 3]\n",
      " |  TRAIN: [1 2 4 0] TEST: [3 5]\n",
      " |  TRAIN: [3 4 1 0] TEST: [5 2]\n",
      " |  TRAIN: [3 5 1 0] TEST: [2 4]\n",
      " |  >>> rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,\n",
      " |  ...                   random_state=0)\n",
      " |  >>> for train_index, test_index in rs.split(X):\n",
      " |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  TRAIN: [1 3 0] TEST: [5 2]\n",
      " |  TRAIN: [4 0 2] TEST: [1 3]\n",
      " |  TRAIN: [1 2 4] TEST: [3 5]\n",
      " |  TRAIN: [3 4 1] TEST: [5 2]\n",
      " |  TRAIN: [3 5 1] TEST: [2 4]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ShuffleSplit\n",
      " |      BaseShuffleSplit\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseShuffleSplit:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  split(self, X, y=None, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training data, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target variable for supervised learning problems.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Randomized CV splitters may return different results for each call of\n",
      " |      split. You can make the results identical by setting `random_state`\n",
      " |      to an integer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseShuffleSplit:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "help(ShuffleSplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Estimate the performance of your model with 10 shuffle splits on your data. Take care to correctly normalize your data. Your code here must do everything since the beginning, ie. loading the data, splitting, cv, prediction, etc... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[14069 17482  7362 ...  9845 10799  2732]\n",
      "  Test:  index=[14740 10101 20566 ... 16212  6944  8746]\n",
      "  Train MAE: 0.5305120529578005\n",
      "  Test MAE: 0.5342632063167858\n",
      "Fold 1:\n",
      "  Train: index=[13275  5966 15304 ...  5154 14875  2751]\n",
      "  Test:  index=[ 9959 16306 17662 ...  4465  3775 17089]\n",
      "  Train MAE: 0.5253541754031219\n",
      "  Test MAE: 0.5388933598081989\n",
      "Fold 2:\n",
      "  Train: index=[ 9550  9151 16135 ...  9972  1146   747]\n",
      "  Test:  index=[20340 18230 15362 ...  4357   361  8513]\n",
      "  Train MAE: 0.5271310597039717\n",
      "  Test MAE: 0.5334177645651994\n",
      "Fold 3:\n",
      "  Train: index=[19727  5450 19077 ... 14722  5851 12988]\n",
      "  Test:  index=[ 5313  7640 18918 ...  6280  9648  4514]\n",
      "  Train MAE: 0.5360922067185766\n",
      "  Test MAE: 0.5220989338290791\n",
      "Fold 4:\n",
      "  Train: index=[13442  5378  3557 ...   526  6465  9283]\n",
      "  Test:  index=[ 7357  4713 10050 ... 13043  2269  3193]\n",
      "  Train MAE: 0.5301460051938748\n",
      "  Test MAE: 0.5347483819065451\n",
      "Fold 5:\n",
      "  Train: index=[ 6865 18984  3873 ... 10572 16502 14054]\n",
      "  Test:  index=[10502 14461 10915 ... 11523  1774  7235]\n",
      "  Train MAE: 0.5327052800720696\n",
      "  Test MAE: 0.5252468568182835\n",
      "Fold 6:\n",
      "  Train: index=[12829  3055 10503 ... 13881  1853 13042]\n",
      "  Test:  index=[13182  1320  2362 ...  1713  3346  5603]\n",
      "  Train MAE: 0.529827883890555\n",
      "  Test MAE: 0.5309920732211422\n",
      "Fold 7:\n",
      "  Train: index=[10032  6737 18032 ... 10609  1597 11674]\n",
      "  Test:  index=[ 3344   302 20417 ... 11811  9485 20285]\n",
      "  Train MAE: 0.5324226307668553\n",
      "  Test MAE: 0.5320940940522065\n",
      "Fold 8:\n",
      "  Train: index=[ 1523   976  6465 ...  2442 16057 18358]\n",
      "  Test:  index=[ 5997   295  2025 ... 10712  3114 15457]\n",
      "  Train MAE: 0.5316127335651829\n",
      "  Test MAE: 0.5268362589709422\n",
      "Fold 9:\n",
      "  Train: index=[ 8907 19479 10923 ... 19800  6174 10120]\n",
      "  Test:  index=[ 6580 14013 12559 ...  1886 16194  1064]\n",
      "  Train MAE: 0.526327918188408\n",
      "  Test MAE: 0.5367704996352796\n",
      "[['Train score', 'Test score'], [0.5305120529578005, 0.5342632063167858], [0.5253541754031219, 0.5388933598081989], [0.5271310597039717, 0.5334177645651994], [0.5360922067185766, 0.5220989338290791], [0.5301460051938748, 0.5347483819065451], [0.5327052800720696, 0.5252468568182835], [0.529827883890555, 0.5309920732211422], [0.5324226307668553, 0.5320940940522065], [0.5316127335651829, 0.5268362589709422], [0.526327918188408, 0.5367704996352796]]\n"
     ]
    }
   ],
   "source": [
    "rs = ShuffleSplit(n_splits=10, test_size=.33, random_state=0)\n",
    "X_scaled=StandardScaler().fit_transform(X)\n",
    "scores = [[\"Train score\", \"Test score\"]]\n",
    "for i, (train_index, test_index) in enumerate(rs.split(X_scaled,y)):\n",
    "    ridge_rs=Ridge()\n",
    "    X_train_rs, X_test_rs = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_rs, y_test_rs = y[train_index], y[test_index]\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    ridge_rs.fit(X_train_rs, y_train_rs)\n",
    "    y_pred_train_rs = ridge_rs.predict(X_train_rs)\n",
    "    print(f\"  Train MAE: {mean_absolute_error(y_train_rs,y_pred_train_rs)}\")\n",
    "    y_pred_test_rs = ridge_rs.predict(X_test_rs)\n",
    "    print(f\"  Test MAE: {mean_absolute_error(y_test_rs,y_pred_test_rs)}\")\n",
    "    scores.append([mean_absolute_error(y_train_rs,y_pred_train_rs),mean_absolute_error(y_test_rs,y_pred_test_rs)])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "An alternative to Ridge Regression is the Lasso Regression ([check here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)). Lasso Regression redefines the penalization term to the L1-norm of $\\mathbf{w}$. This penalization ensures a sparsity constraint on the coefficients of $\\mathbf{w}$. \n",
    "\n",
    "1. Learn your model using a Lasso Regression, available with the class `Lasso` of module `sklearn.linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Lasso in module sklearn.linear_model._coordinate_descent:\n",
      "\n",
      "class Lasso(ElasticNet)\n",
      " |  Lasso(alpha=1.0, *, fit_intercept=True, normalize='deprecated', precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |  \n",
      " |  Linear Model trained with L1 prior as regularizer (aka the Lasso).\n",
      " |  \n",
      " |  The optimization objective for Lasso is::\n",
      " |  \n",
      " |      (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      " |  \n",
      " |  Technically the Lasso model is optimizing the same objective function as\n",
      " |  the Elastic Net with ``l1_ratio=1.0`` (no L2 penalty).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <lasso>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : float, default=1.0\n",
      " |      Constant that multiplies the L1 term, controlling regularization\n",
      " |      strength. `alpha` must be a non-negative float i.e. in `[0, inf)`.\n",
      " |  \n",
      " |      When `alpha = 0`, the objective is equivalent to ordinary least\n",
      " |      squares, solved by the :class:`LinearRegression` object. For numerical\n",
      " |      reasons, using `alpha = 0` with the `Lasso` object is not advised.\n",
      " |      Instead, you should use the :class:`LinearRegression` object.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be centered).\n",
      " |  \n",
      " |  normalize : bool, default=False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          ``normalize`` was deprecated in version 1.0 and will be removed in\n",
      " |          1.2.\n",
      " |  \n",
      " |  precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      " |      Whether to use a precomputed Gram matrix to speed up\n",
      " |      calculations. The Gram matrix can also be passed as argument.\n",
      " |      For sparse input this option is always ``False`` to preserve sparsity.\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If ``True``, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  max_iter : int, default=1000\n",
      " |      The maximum number of iterations.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      The tolerance for the optimization: if the updates are\n",
      " |      smaller than ``tol``, the optimization code checks the\n",
      " |      dual gap for optimality and continues until it is smaller\n",
      " |      than ``tol``, see Notes below.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  positive : bool, default=False\n",
      " |      When set to ``True``, forces the coefficients to be positive.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      The seed of the pseudo random number generator that selects a random\n",
      " |      feature to update. Used when ``selection`` == 'random'.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      " |      If set to 'random', a random coefficient is updated every iteration\n",
      " |      rather than looping over features sequentially by default. This\n",
      " |      (setting to 'random') often leads to significantly faster convergence\n",
      " |      especially when tol is higher than 1e-4.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      " |      Parameter vector (w in the cost function formula).\n",
      " |  \n",
      " |  dual_gap_ : float or ndarray of shape (n_targets,)\n",
      " |      Given param alpha, the dual gaps at the end of the optimization,\n",
      " |      same shape as each observation of y.\n",
      " |  \n",
      " |  sparse_coef_ : sparse matrix of shape (n_features, 1) or             (n_targets, n_features)\n",
      " |      Readonly property derived from ``coef_``.\n",
      " |  \n",
      " |  intercept_ : float or ndarray of shape (n_targets,)\n",
      " |      Independent term in decision function.\n",
      " |  \n",
      " |  n_iter_ : int or list of int\n",
      " |      Number of iterations run by the coordinate descent solver to reach\n",
      " |      the specified tolerance.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  lars_path : Regularization path using LARS.\n",
      " |  lasso_path : Regularization path using Lasso.\n",
      " |  LassoLars : Lasso Path along the regularization parameter usingLARS algorithm.\n",
      " |  LassoCV : Lasso alpha parameter by cross-validation.\n",
      " |  LassoLarsCV : Lasso least angle parameter algorithm by cross-validation.\n",
      " |  sklearn.decomposition.sparse_encode : Sparse coding array estimator.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The algorithm used to fit the model is coordinate descent.\n",
      " |  \n",
      " |  To avoid unnecessary memory duplication the X argument of the fit method\n",
      " |  should be directly passed as a Fortran-contiguous numpy array.\n",
      " |  \n",
      " |  Regularization improves the conditioning of the problem and\n",
      " |  reduces the variance of the estimates. Larger values specify stronger\n",
      " |  regularization. Alpha corresponds to `1 / (2C)` in other linear\n",
      " |  models such as :class:`~sklearn.linear_model.LogisticRegression` or\n",
      " |  :class:`~sklearn.svm.LinearSVC`. If an array is passed, penalties are\n",
      " |  assumed to be specific to the targets. Hence they must correspond in\n",
      " |  number.\n",
      " |  \n",
      " |  The precise stopping criteria based on `tol` are the following: First, check that\n",
      " |  that maximum coordinate update, i.e. :math:`\\max_j |w_j^{new} - w_j^{old}|`\n",
      " |  is smaller than `tol` times the maximum absolute coefficient, :math:`\\max_j |w_j|`.\n",
      " |  If so, then additionally check whether the dual gap is smaller than `tol` times\n",
      " |  :math:`||y||_2^2 / n_{      ext{samples}}`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import linear_model\n",
      " |  >>> clf = linear_model.Lasso(alpha=0.1)\n",
      " |  >>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
      " |  Lasso(alpha=0.1)\n",
      " |  >>> print(clf.coef_)\n",
      " |  [0.85 0.  ]\n",
      " |  >>> print(clf.intercept_)\n",
      " |  0.15...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Lasso\n",
      " |      ElasticNet\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.linear_model._base.LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, *, fit_intercept=True, normalize='deprecated', precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      " |      Compute elastic net path with coordinate descent.\n",
      " |      \n",
      " |      The elastic net optimization function varies for mono and multi-outputs.\n",
      " |      \n",
      " |      For mono-output tasks it is::\n",
      " |      \n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |      \n",
      " |      For multi-output tasks it is::\n",
      " |      \n",
      " |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      " |          + alpha * l1_ratio * ||W||_21\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      " |      \n",
      " |      Where::\n",
      " |      \n",
      " |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      " |      \n",
      " |      i.e. the sum of norm of each row.\n",
      " |      \n",
      " |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      " |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      " |          can be sparse.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      " |          Target values.\n",
      " |      \n",
      " |      l1_ratio : float, default=0.5\n",
      " |          Number between 0 and 1 passed to elastic net (scaling between\n",
      " |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      " |      \n",
      " |      eps : float, default=1e-3\n",
      " |          Length of the path. ``eps=1e-3`` means that\n",
      " |          ``alpha_min / alpha_max = 1e-3``.\n",
      " |      \n",
      " |      n_alphas : int, default=100\n",
      " |          Number of alphas along the regularization path.\n",
      " |      \n",
      " |      alphas : ndarray, default=None\n",
      " |          List of alphas where to compute the models.\n",
      " |          If None alphas are set automatically.\n",
      " |      \n",
      " |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      " |          Whether to use a precomputed Gram matrix to speed up\n",
      " |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      " |          matrix can also be passed as argument.\n",
      " |      \n",
      " |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      " |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      " |          only when the Gram matrix is precomputed.\n",
      " |      \n",
      " |      copy_X : bool, default=True\n",
      " |          If ``True``, X will be copied; else, it may be overwritten.\n",
      " |      \n",
      " |      coef_init : ndarray of shape (n_features, ), default=None\n",
      " |          The initial values of the coefficients.\n",
      " |      \n",
      " |      verbose : bool or int, default=False\n",
      " |          Amount of verbosity.\n",
      " |      \n",
      " |      return_n_iter : bool, default=False\n",
      " |          Whether to return the number of iterations or not.\n",
      " |      \n",
      " |      positive : bool, default=False\n",
      " |          If set to True, forces coefficients to be positive.\n",
      " |          (Only allowed when ``y.ndim == 1``).\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          If set to False, the input validation checks are skipped (including the\n",
      " |          Gram matrix when provided). It is assumed that they are handled\n",
      " |          by the caller.\n",
      " |      \n",
      " |      **params : kwargs\n",
      " |          Keyword arguments passed to the coordinate descent solver.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      alphas : ndarray of shape (n_alphas,)\n",
      " |          The alphas along the path where models are computed.\n",
      " |      \n",
      " |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      " |          Coefficients along the path.\n",
      " |      \n",
      " |      dual_gaps : ndarray of shape (n_alphas,)\n",
      " |          The dual gaps at the end of the optimization for each alpha.\n",
      " |      \n",
      " |      n_iters : list of int\n",
      " |          The number of iterations taken by the coordinate descent optimizer to\n",
      " |          reach the specified tolerance for each alpha.\n",
      " |          (Is returned when ``return_n_iter`` is set to True).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      " |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      " |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      " |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For an example, see\n",
      " |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      " |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ElasticNet:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True)\n",
      " |      Fit model with coordinate descent.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {ndarray, sparse matrix} of (n_samples, n_features)\n",
      " |          Data.\n",
      " |      \n",
      " |      y : {ndarray, sparse matrix} of shape (n_samples,) or             (n_samples, n_targets)\n",
      " |          Target. Will be cast to X's dtype if necessary.\n",
      " |      \n",
      " |      sample_weight : float or array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. Internally, the `sample_weight` vector will be\n",
      " |          rescaled to sum to `n_samples`.\n",
      " |      \n",
      " |          .. versionadded:: 0.23\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Coordinate descent is an algorithm that considers each column of\n",
      " |      data at a time hence it will automatically convert the X input\n",
      " |      as a Fortran-contiguous numpy array if necessary.\n",
      " |      \n",
      " |      To avoid memory re-allocation it is advised to allocate the\n",
      " |      initial data in memory directly using that format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from ElasticNet:\n",
      " |  \n",
      " |  sparse_coef_\n",
      " |      Sparse representation of the fitted `coef_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "help(Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check the regularization path, i.e. the evolution of $\\mathbf{w}$ as $\\lambda$ increases. Do you see the sparsity ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_142383/3924293006.py:4: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(X_train_norm,y_train_norm)\n",
      "/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/elnur/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.692e+03, tolerance: 1.383e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.72993779,  0.10252163, -0.23016047,  0.25052135, -0.00792305,\n",
       "        -0.02394052, -0.76030931, -0.7373548 ]),\n",
       " array([ 0.63624692,  0.11511916, -0.        ,  0.01361463, -0.        ,\n",
       "        -0.0065402 , -0.5154268 , -0.48043612]),\n",
       " array([ 0.64389287,  0.12271685, -0.        ,  0.        ,  0.        ,\n",
       "        -0.        , -0.20160185, -0.16684404]),\n",
       " array([ 0.6374753 ,  0.11552254, -0.        , -0.        ,  0.        ,\n",
       "        -0.        , -0.02547164, -0.        ]),\n",
       " array([ 0.61406905,  0.09011078, -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.00472871, -0.        ]),\n",
       " array([ 0.58929866,  0.06488322, -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ]),\n",
       " array([ 0.5641255 ,  0.03971005, -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ]),\n",
       " array([ 0.53895202,  0.01453684, -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ]),\n",
       " array([ 0.51502602,  0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ]),\n",
       " array([ 0.49280379,  0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ])]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs=[]\n",
    "for alpha in np.linspace(0,0.2,10):\n",
    "    lasso=Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_norm,y_train_norm)\n",
    "    coefs.append(lasso.coef_)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Build and tune completly your Lasso model and compare its final performance with Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE for lasso:  0.7885621590317375\n",
      "Test MAE for lasso:  0.7931669699224003\n",
      "Train MAE for ridge:  0.4595601477008113\n",
      "Test MAE for ridge:  0.461470085494359\n"
     ]
    }
   ],
   "source": [
    "lasso=Lasso()\n",
    "lasso.fit(X_train_norm, y_train_norm)\n",
    "y_pred_train=lasso.predict(X_train_norm)\n",
    "y_pred_test=lasso.predict(X_test_norm)\n",
    "print(\"Train MAE for lasso: \",mean_absolute_error(y_train_norm, y_pred_train))\n",
    "print(\"Test MAE for lasso: \",mean_absolute_error(y_test_norm, y_pred_test))\n",
    "\n",
    "ridge=Ridge()\n",
    "ridge.fit(X_train_norm, y_train_norm)\n",
    "y_pred_train=ridge.predict(X_train_norm)\n",
    "y_pred_test=ridge.predict(X_test_norm)\n",
    "print(\"Train MAE for ridge: \",mean_absolute_error(y_train_norm, y_pred_train))\n",
    "print(\"Test MAE for ridge: \",mean_absolute_error(y_test_norm, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus section\n",
    "\n",
    "If you succeed to previous parts, here's some suggestions to continue and go deeper in your work:\n",
    "\n",
    " 1. Use your implementation of Ridge Regression. Compare the computationnal times.\n",
    " \n",
    " 2. Implement your own Cross Validation strategy. `sklearn` provides beautiful tools but it may be interesting to implement yourself this protocol to understand it deeply.\n",
    " \n",
    " 3. Make the derivation and implement your own Lasso Regression. \n",
    " \n",
    " 4. Implement and evaluate your model on a diabetes dataset `sklearn.datasets.load_diabetes`. Take care, some columns correspond to qualitative features. [link](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990749, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06833155, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286131, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04688253,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452873, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00422151,  0.00306441]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_load=sklearn.datasets.load_diabetes()[\"data\"]\n",
    "X_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_load=sklearn.datasets.load_diabetes()[\"target\"]\n",
    "y_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_load, y_load, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.324304021812644"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, lasso.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.59741827324625"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, lasso.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
